# ğŸŒ± ESG-Sustainability Analysis Dashboard

[![Python](https://img.shields.io/badge/python-v3.10+-blue.svg)](https://www.python.org/downloads/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-v15+-blue.svg)](https://www.postgresql.org/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

An interactive ESG (Environmental, Social, Governance) analytics dashboard that helps analysts, investors, and sustainability officers evaluate ESG performance across companies and industries. This project integrates PostgreSQL for data management and Power BI/Dash for visualization.

## ğŸŒŸ Key Features

- Company-level ESG score analysis (Total ESG + E/S/G sub-scores)
- Sector and industry benchmarking
- Controversy risk assessment
- Interactive dashboards with filters for sector, company, and ESG risk level
- Optional ML model to predict ESG Risk Level (Low / Medium / High)

## ğŸ“ Project Structure
```
â”œâ”€â”€ backend/                # FastAPI application & database utilities
â”‚   â”œâ”€â”€ app.py              # API entrypoint (analytics + prediction)
â”‚   â”œâ”€â”€ db_config.py        # PostgreSQL connection configuration
â”‚   â”œâ”€â”€ utils.py            # Reusable DB helpers
â”‚   â”œâ”€â”€ model.py            # Model load & inference helpers
â”‚   â”œâ”€â”€ schemas.py          # Pydantic request/response models
â”‚   â””â”€â”€ sql/                # SQL assets (schema, load, analysis queries)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # Original input dataset(s)
â”‚   â””â”€â”€ processed/          # Cleaned & feature engineered datasets
â”œâ”€â”€ notebooks/              # Jupyter notebooks (cleaning, EDA, modeling, integration)
â”œâ”€â”€ scripts/                # Automation scripts (load db, train model, predict)
â”œâ”€â”€ reports/                # Generated reports, figures, prediction outputs
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ .env                    # Environment variables (NOT COMMITTED)
â””â”€â”€ README.md               # Project documentation
```

## ğŸ—„ï¸ Database Setup
1. Create a PostgreSQL database (default name: `esg_db`).
2. Populate a `.env` file at repo root:
```
DB_HOST=localhost
DB_PORT=5432
DB_NAME=esg_db
DB_USER=postgres
DB_PASSWORD=yourpassword
```
3. Apply schema:
```
psql -h localhost -U postgres -d esg_db -f backend/sql/schema.sql
```
4. (Optional) Load data via COPY (adjust path first) using `backend/sql/load_data.sql`.

## ğŸš€ Running the API
Install dependencies then start FastAPI with Uvicorn:
```
pip install -r requirements.txt
python -m uvicorn backend.app:app --reload --port 8000
```
Open: http://localhost:8000/docs for interactive Swagger.

## ğŸ¤– Training the Model
Prepare a processed CSV containing features:
Required columns: `environment_risk_score, social_risk_score, governance_risk_score, controversy_score, full_time_employees, esg_risk_level`
```
python scripts/train_model.py --input data/processed/esg_model_training.csv --output models/esg_risk_model.joblib
```
After training restart the API (it auto-loads the model at startup).

## ğŸ”® Making Predictions (Batch)
```
python scripts/predict.py --input data/processed/new_companies.csv --output reports/predictions/predictions.csv
```

Or via API:
```
POST /predict
{
	"environment_risk_score": 12.3,
	"social_risk_score": 18.4,
	"governance_risk_score": 10.2,
	"controversy_score": 25.0,
	"full_time_employees": 34000
}
```

## ğŸ“Š Key Endpoints
| Endpoint | Description |
|----------|-------------|
| `/health` | Health & readiness (DB + model) |
| `/companies/top?limit=10` | Lowest ESG risk companies |
| `/sectors/average` | Sector-level average scores |
| `/companies/high-controversy?min_score=50` | High controversy filter |
| `/predict` | Single prediction |
| `/predict/batch` | Batch predictions |

## âœ… Data Quality & Reproducibility
Notebooks provide a transparent lineage from raw data â†’ cleaned â†’ modeling dataset. Scripts operationalize those flows for automation / scheduling.

## ğŸ§ª Testing (Suggested Additions)
Add unit tests for:
- DB utility functions (mocked connection)
- Model prediction shape
- API endpoint responses (TestClient)

## ğŸ” Security Notes
- Restrict `allow_origins` in production.
- Use role-based DB credentials with least privilege.
- Consider adding rate limiting & API key auth for hosted deployment.

## ğŸ“Œ Roadmap Ideas
- Add CI workflow (lint + tests + Docker build)
- Feature importance & SHAP analysis endpoint
- Incremental data ingestion pipeline (Airflow / Prefect)
- Dashboard container (Dash or Streamlit) with reverse proxy

## ğŸ“ License
MIT License. See `LICENSE` for details.

---
If you find this useful, a star â­ on the repository helps others discover it.

