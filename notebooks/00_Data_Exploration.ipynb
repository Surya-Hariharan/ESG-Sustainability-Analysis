{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eec2095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "pd.set_option('display.width', 120)\n",
    "\n",
    "print('Libraries imported successfully')\n",
    "print(f'Pandas version: {pd.__version__}')\n",
    "print(f'NumPy version: {np.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a55674b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('../data/raw/dataset.csv')\n",
    "\n",
    "if not DATA_PATH.exists():\n",
    "    raise FileNotFoundError(f'Dataset not found at: {DATA_PATH}')\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(f'Dataset loaded from: {DATA_PATH}')\n",
    "print(f'Dataset shape: {df.shape[0]:,} rows x {df.shape[1]} columns')\n",
    "print(f'Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB')\n",
    "print(f'Load timestamp: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c8d061",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('DATASET PREVIEW - First 10 Rows')\n",
    "print('=' * 120)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c60e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('DATASET PREVIEW - Last 10 Rows')\n",
    "print('=' * 120)\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa9906f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('DATASET PREVIEW - Random 10 Rows')\n",
    "print('=' * 120)\n",
    "df.sample(10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d3286b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('DATASET STRUCTURE AND METADATA')\n",
    "print('=' * 120)\n",
    "df.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4dee77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('COLUMN NAMES AND DATA TYPES')\n",
    "print('=' * 120)\n",
    "\n",
    "column_info = pd.DataFrame({\n",
    "    'Column_Name': df.columns,\n",
    "    'Data_Type': df.dtypes.values,\n",
    "    'Non_Null_Count': df.count().values,\n",
    "    'Null_Count': df.isnull().sum().values,\n",
    "    'Null_Percentage': (df.isnull().sum() / len(df) * 100).values\n",
    "})\n",
    "\n",
    "column_info.index = range(1, len(column_info) + 1)\n",
    "column_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1f3a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('STATISTICAL SUMMARY - NUMERICAL FEATURES')\n",
    "print('=' * 120)\n",
    "df.describe(include=[np.number]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ea2937",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('STATISTICAL SUMMARY - CATEGORICAL FEATURES')\n",
    "print('=' * 120)\n",
    "df.describe(include=['object']).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3261544b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MISSING VALUES ANALYSIS')\n",
    "print('=' * 120)\n",
    "\n",
    "missing_data = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing_Count': df.isnull().sum().values,\n",
    "    'Missing_Percentage': (df.isnull().sum() / len(df) * 100).values,\n",
    "    'Data_Type': df.dtypes.values\n",
    "}).sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "missing_data = missing_data[missing_data['Missing_Count'] > 0]\n",
    "\n",
    "if len(missing_data) > 0:\n",
    "    print(f'Total columns with missing values: {len(missing_data)}')\n",
    "    print(f'Total missing values: {missing_data[\"Missing_Count\"].sum():,}')\n",
    "    print('\\nDetailed breakdown:')\n",
    "    missing_data.index = range(1, len(missing_data) + 1)\n",
    "    display(missing_data)\n",
    "else:\n",
    "    print('No missing values detected in dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e04ba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MISSING VALUES HEATMAP')\n",
    "print('=' * 120)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "sns.heatmap(df.isnull(), cbar=True, cmap='viridis', yticklabels=False, ax=ax)\n",
    "ax.set_title('Missing Values Heatmap (Yellow = Missing)', fontsize=14, fontweight='bold', pad=20)\n",
    "ax.set_xlabel('Columns', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Rows', fontsize=12, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "total_cells = np.product(df.shape)\n",
    "total_missing = df.isnull().sum().sum()\n",
    "print(f'\\nTotal cells: {total_cells:,}')\n",
    "print(f'Missing cells: {total_missing:,} ({total_missing/total_cells*100:.2f}%)')\n",
    "print(f'Complete cells: {total_cells - total_missing:,} ({(total_cells - total_missing)/total_cells*100:.2f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac7039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('DUPLICATE RECORDS ANALYSIS')\n",
    "print('=' * 120)\n",
    "\n",
    "total_duplicates = df.duplicated().sum()\n",
    "duplicate_percentage = (total_duplicates / len(df)) * 100\n",
    "\n",
    "print(f'Total records: {len(df):,}')\n",
    "print(f'Duplicate records: {total_duplicates:,} ({duplicate_percentage:.2f}%)')\n",
    "print(f'Unique records: {len(df) - total_duplicates:,} ({100 - duplicate_percentage:.2f}%)')\n",
    "\n",
    "if total_duplicates > 0:\n",
    "    print('\\nDuplicate records preview:')\n",
    "    display(df[df.duplicated(keep=False)].sort_values(by=df.columns[0]).head(20))\n",
    "else:\n",
    "    print('\\nNo duplicate records found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96100cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('DATA TYPES DISTRIBUTION')\n",
    "print('=' * 120)\n",
    "\n",
    "dtype_counts = df.dtypes.value_counts()\n",
    "print(dtype_counts)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "dtype_counts.plot(kind='bar', color='steelblue', edgecolor='black', ax=ax)\n",
    "ax.set_title('Data Types Distribution', fontsize=14, fontweight='bold', pad=20)\n",
    "ax.set_xlabel('Data Type', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Count', fontsize=12, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c67b420",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('NUMERICAL FEATURES DISTRIBUTION - HISTOGRAMS')\n",
    "print('=' * 120)\n",
    "\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f'Total numerical features: {len(numerical_cols)}')\n",
    "print(f'Features: {numerical_cols}\\n')\n",
    "\n",
    "if len(numerical_cols) > 0:\n",
    "    n_cols = 3\n",
    "    n_rows = (len(numerical_cols) + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, n_rows * 4))\n",
    "    axes = axes.flatten() if len(numerical_cols) > 1 else [axes]\n",
    "    \n",
    "    for idx, col in enumerate(numerical_cols):\n",
    "        ax = axes[idx]\n",
    "        data = df[col].dropna()\n",
    "        \n",
    "        ax.hist(data, bins=40, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "        ax.axvline(data.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {data.mean():.2f}')\n",
    "        ax.axvline(data.median(), color='orange', linestyle='--', linewidth=2, label=f'Median: {data.median():.2f}')\n",
    "        ax.set_title(col, fontsize=11, fontweight='bold')\n",
    "        ax.set_xlabel('Value', fontsize=9)\n",
    "        ax.set_ylabel('Frequency', fontsize=9)\n",
    "        ax.legend(fontsize=8)\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    for idx in range(len(numerical_cols), len(axes)):\n",
    "        fig.delaxes(axes[idx])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No numerical features found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286e4f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('NUMERICAL FEATURES - BOX PLOTS (OUTLIER DETECTION)')\n",
    "print('=' * 120)\n",
    "\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "if len(numerical_cols) > 0:\n",
    "    n_cols = 3\n",
    "    n_rows = (len(numerical_cols) + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, n_rows * 4))\n",
    "    axes = axes.flatten() if len(numerical_cols) > 1 else [axes]\n",
    "    \n",
    "    for idx, col in enumerate(numerical_cols):\n",
    "        ax = axes[idx]\n",
    "        data = df[col].dropna()\n",
    "        \n",
    "        bp = ax.boxplot(data, vert=True, patch_artist=True,\n",
    "                        boxprops=dict(facecolor='lightblue', alpha=0.7),\n",
    "                        whiskerprops=dict(color='black'),\n",
    "                        capprops=dict(color='black'),\n",
    "                        medianprops=dict(color='red', linewidth=2))\n",
    "        \n",
    "        ax.set_title(col, fontsize=11, fontweight='bold')\n",
    "        ax.set_ylabel('Value', fontsize=9)\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        q1 = data.quantile(0.25)\n",
    "        q3 = data.quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        outliers = ((data < (q1 - 1.5 * iqr)) | (data > (q3 + 1.5 * iqr))).sum()\n",
    "        \n",
    "        ax.text(0.5, 0.95, f'Outliers: {outliers}', transform=ax.transAxes,\n",
    "                fontsize=9, verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    for idx in range(len(numerical_cols), len(axes)):\n",
    "        fig.delaxes(axes[idx])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No numerical features found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebca2a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CORRELATION MATRIX - NUMERICAL FEATURES')\n",
    "print('=' * 120)\n",
    "\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "if len(numerical_cols) >= 2:\n",
    "    correlation_matrix = df[numerical_cols].corr()\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "    \n",
    "    sns.heatmap(correlation_matrix, annot=True, fmt='.3f', cmap='RdYlBu_r',\n",
    "                square=True, linewidths=1, cbar_kws={'shrink': 0.8},\n",
    "                vmin=-1, vmax=1, center=0, ax=axes[0])\n",
    "    axes[0].set_title('Full Correlation Matrix', fontsize=14, fontweight='bold', pad=20)\n",
    "    \n",
    "    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "    sns.heatmap(correlation_matrix, mask=mask, annot=True, fmt='.3f', cmap='RdYlBu_r',\n",
    "                square=True, linewidths=1, cbar_kws={'shrink': 0.8},\n",
    "                vmin=-1, vmax=1, center=0, ax=axes[1])\n",
    "    axes[1].set_title('Lower Triangle Correlation Matrix', fontsize=14, fontweight='bold', pad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print('\\nHigh Correlations (|r| > 0.7):')\n",
    "    high_corr = []\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i+1, len(correlation_matrix.columns)):\n",
    "            if abs(correlation_matrix.iloc[i, j]) > 0.7:\n",
    "                high_corr.append({\n",
    "                    'Feature_1': correlation_matrix.columns[i],\n",
    "                    'Feature_2': correlation_matrix.columns[j],\n",
    "                    'Correlation': correlation_matrix.iloc[i, j]\n",
    "                })\n",
    "    \n",
    "    if high_corr:\n",
    "        high_corr_df = pd.DataFrame(high_corr).sort_values('Correlation', key=abs, ascending=False)\n",
    "        display(high_corr_df)\n",
    "    else:\n",
    "        print('No high correlations found')\n",
    "else:\n",
    "    print('Insufficient numerical features for correlation analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b42ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CATEGORICAL FEATURES - VALUE COUNTS')\n",
    "print('=' * 120)\n",
    "\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f'Total categorical features: {len(categorical_cols)}')\n",
    "print(f'Features: {categorical_cols}\\n')\n",
    "\n",
    "if len(categorical_cols) > 0:\n",
    "    for col in categorical_cols:\n",
    "        print(f'\\n{col}:')\n",
    "        print('-' * 60)\n",
    "        value_counts = df[col].value_counts()\n",
    "        value_percentage = (df[col].value_counts(normalize=True) * 100).round(2)\n",
    "        \n",
    "        result = pd.DataFrame({\n",
    "            'Count': value_counts,\n",
    "            'Percentage': value_percentage\n",
    "        })\n",
    "        \n",
    "        print(result.head(20))\n",
    "        \n",
    "        if len(value_counts) > 20:\n",
    "            print(f'... and {len(value_counts) - 20} more unique values')\n",
    "        \n",
    "        print(f'Total unique values: {len(value_counts)}')\n",
    "else:\n",
    "    print('No categorical features found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ce0847",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CATEGORICAL FEATURES - DISTRIBUTION CHARTS')\n",
    "print('=' * 120)\n",
    "\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "if len(categorical_cols) > 0:\n",
    "    for col in categorical_cols:\n",
    "        value_counts = df[col].value_counts()\n",
    "        \n",
    "        if len(value_counts) <= 20:\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "            \n",
    "            value_counts.plot(kind='bar', color='steelblue', edgecolor='black', alpha=0.7, ax=axes[0])\n",
    "            axes[0].set_title(f'{col} - Bar Chart', fontsize=12, fontweight='bold')\n",
    "            axes[0].set_xlabel('Category', fontsize=10)\n",
    "            axes[0].set_ylabel('Count', fontsize=10)\n",
    "            axes[0].tick_params(axis='x', rotation=45)\n",
    "            axes[0].grid(axis='y', alpha=0.3)\n",
    "            \n",
    "            value_counts.plot(kind='pie', autopct='%1.1f%%', startangle=90, ax=axes[1])\n",
    "            axes[1].set_title(f'{col} - Pie Chart', fontsize=12, fontweight='bold')\n",
    "            axes[1].set_ylabel('')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            fig, ax = plt.subplots(figsize=(14, 6))\n",
    "            value_counts.head(20).plot(kind='bar', color='steelblue', edgecolor='black', alpha=0.7, ax=ax)\n",
    "            ax.set_title(f'{col} - Top 20 Values', fontsize=12, fontweight='bold')\n",
    "            ax.set_xlabel('Category', fontsize=10)\n",
    "            ax.set_ylabel('Count', fontsize=10)\n",
    "            ax.tick_params(axis='x', rotation=45)\n",
    "            ax.grid(axis='y', alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "else:\n",
    "    print('No categorical features found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38deeff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('FEATURE UNIQUENESS ANALYSIS')\n",
    "print('=' * 120)\n",
    "\n",
    "uniqueness_data = []\n",
    "for col in df.columns:\n",
    "    unique_count = df[col].nunique()\n",
    "    unique_percentage = (unique_count / len(df)) * 100\n",
    "    uniqueness_data.append({\n",
    "        'Feature': col,\n",
    "        'Unique_Values': unique_count,\n",
    "        'Unique_Percentage': unique_percentage,\n",
    "        'Data_Type': df[col].dtype\n",
    "    })\n",
    "\n",
    "uniqueness_df = pd.DataFrame(uniqueness_data).sort_values('Unique_Values', ascending=False)\n",
    "uniqueness_df.index = range(1, len(uniqueness_df) + 1)\n",
    "uniqueness_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cb3f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('INTERACTIVE SCATTER PLOT - NUMERICAL FEATURES (PLOTLY)')\n",
    "print('=' * 120)\n",
    "\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "if len(numerical_cols) >= 2:\n",
    "    x_col = numerical_cols[0]\n",
    "    y_col = numerical_cols[1] if len(numerical_cols) > 1 else numerical_cols[0]\n",
    "    \n",
    "    size_col = numerical_cols[2] if len(numerical_cols) > 2 else None\n",
    "    color_col = df.select_dtypes(include=['object']).columns[0] if len(df.select_dtypes(include=['object']).columns) > 0 else None\n",
    "    \n",
    "    fig = px.scatter(\n",
    "        df,\n",
    "        x=x_col,\n",
    "        y=y_col,\n",
    "        size=size_col,\n",
    "        color=color_col,\n",
    "        hover_data=df.columns.tolist(),\n",
    "        title=f'Interactive Scatter: {x_col} vs {y_col}',\n",
    "        opacity=0.7,\n",
    "        size_max=30\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        height=700,\n",
    "        font=dict(size=12),\n",
    "        title_font=dict(size=16, family='Arial Black'),\n",
    "        hovermode='closest'\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    print(f'X-axis: {x_col}')\n",
    "    print(f'Y-axis: {y_col}')\n",
    "    if size_col:\n",
    "        print(f'Bubble size: {size_col}')\n",
    "    if color_col:\n",
    "        print(f'Color: {color_col}')\n",
    "else:\n",
    "    print('Insufficient numerical features for scatter plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95236bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('DATA QUALITY ASSESSMENT')\n",
    "print('=' * 120)\n",
    "\n",
    "quality_metrics = {\n",
    "    'Total Records': len(df),\n",
    "    'Total Features': len(df.columns),\n",
    "    'Numerical Features': len(df.select_dtypes(include=[np.number]).columns),\n",
    "    'Categorical Features': len(df.select_dtypes(include=['object']).columns),\n",
    "    'DateTime Features': len(df.select_dtypes(include=['datetime64']).columns),\n",
    "    'Total Cells': np.product(df.shape),\n",
    "    'Missing Cells': df.isnull().sum().sum(),\n",
    "    'Missing Percentage': f\"{(df.isnull().sum().sum() / np.product(df.shape)) * 100:.2f}%\",\n",
    "    'Duplicate Records': df.duplicated().sum(),\n",
    "    'Duplicate Percentage': f\"{(df.duplicated().sum() / len(df)) * 100:.2f}%\",\n",
    "    'Memory Usage (MB)': f\"{df.memory_usage(deep=True).sum() / 1024**2:.2f}\",\n",
    "    'Complete Records': len(df.dropna()),\n",
    "    'Complete Records Percentage': f\"{(len(df.dropna()) / len(df)) * 100:.2f}%\"\n",
    "}\n",
    "\n",
    "quality_df = pd.DataFrame(list(quality_metrics.items()), columns=['Metric', 'Value'])\n",
    "quality_df.index = range(1, len(quality_df) + 1)\n",
    "quality_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9929d0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('DATASET STRENGTHS')\n",
    "print('=' * 120)\n",
    "\n",
    "strengths = []\n",
    "\n",
    "if df.duplicated().sum() == 0:\n",
    "    strengths.append('No duplicate records detected')\n",
    "\n",
    "missing_pct = (df.isnull().sum().sum() / np.product(df.shape)) * 100\n",
    "if missing_pct < 5:\n",
    "    strengths.append(f'Low missing data: {missing_pct:.2f}%')\n",
    "\n",
    "if len(df) >= 1000:\n",
    "    strengths.append(f'Large dataset: {len(df):,} records')\n",
    "\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "if len(numerical_cols) > 0:\n",
    "    strengths.append(f'{len(numerical_cols)} numerical features for analysis')\n",
    "\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "if len(categorical_cols) > 0:\n",
    "    strengths.append(f'{len(categorical_cols)} categorical features for segmentation')\n",
    "\n",
    "complete_records_pct = (len(df.dropna()) / len(df)) * 100\n",
    "if complete_records_pct > 80:\n",
    "    strengths.append(f'High data completeness: {complete_records_pct:.2f}% complete records')\n",
    "\n",
    "if len(strengths) > 0:\n",
    "    for i, strength in enumerate(strengths, 1):\n",
    "        print(f'{i}. {strength}')\n",
    "else:\n",
    "    print('No specific strengths identified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc4c8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('DATASET WEAKNESSES / FLAWS')\n",
    "print('=' * 120)\n",
    "\n",
    "weaknesses = []\n",
    "\n",
    "missing_pct = (df.isnull().sum().sum() / np.product(df.shape)) * 100\n",
    "if missing_pct > 5:\n",
    "    weaknesses.append(f'Significant missing data: {missing_pct:.2f}%')\n",
    "\n",
    "if df.duplicated().sum() > 0:\n",
    "    weaknesses.append(f'{df.duplicated().sum()} duplicate records found')\n",
    "\n",
    "for col in df.select_dtypes(include=[np.number]).columns:\n",
    "    q1 = df[col].quantile(0.25)\n",
    "    q3 = df[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    outliers = ((df[col] < (q1 - 1.5 * iqr)) | (df[col] > (q3 + 1.5 * iqr))).sum()\n",
    "    outlier_pct = (outliers / len(df)) * 100\n",
    "    if outlier_pct > 10:\n",
    "        weaknesses.append(f'{col}: {outliers} outliers ({outlier_pct:.2f}%)')\n",
    "\n",
    "for col in df.columns:\n",
    "    unique_pct = (df[col].nunique() / len(df)) * 100\n",
    "    if unique_pct > 95 and df[col].dtype == 'object':\n",
    "        weaknesses.append(f'{col}: Very high cardinality ({df[col].nunique()} unique values)')\n",
    "\n",
    "if len(df) < 100:\n",
    "    weaknesses.append(f'Small dataset: only {len(df)} records')\n",
    "\n",
    "skewed_features = []\n",
    "for col in df.select_dtypes(include=[np.number]).columns:\n",
    "    skewness = df[col].skew()\n",
    "    if abs(skewness) > 2:\n",
    "        skewed_features.append(f'{col} (skewness: {skewness:.2f})')\n",
    "\n",
    "if len(skewed_features) > 0:\n",
    "    weaknesses.append(f'Highly skewed features: {len(skewed_features)}')\n",
    "\n",
    "if len(weaknesses) > 0:\n",
    "    for i, weakness in enumerate(weaknesses, 1):\n",
    "        print(f'{i}. {weakness}')\n",
    "else:\n",
    "    print('No significant weaknesses detected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7219d1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('EXPLORATION SUMMARY')\n",
    "print('=' * 120)\n",
    "print(f'Dataset: {DATA_PATH}')\n",
    "print(f'Exploration completed: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "print('=' * 120)\n",
    "print(f'Total Records: {len(df):,}')\n",
    "print(f'Total Features: {len(df.columns)}')\n",
    "print(f'Numerical Features: {len(df.select_dtypes(include=[np.number]).columns)}')\n",
    "print(f'Categorical Features: {len(df.select_dtypes(include=[\"object\"]).columns)}')\n",
    "print(f'Missing Data: {(df.isnull().sum().sum() / np.product(df.shape)) * 100:.2f}%')\n",
    "print(f'Duplicates: {df.duplicated().sum()}')\n",
    "print(f'Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB')\n",
    "print('=' * 120)\n",
    "print('Ready for data cleaning and preprocessing')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
