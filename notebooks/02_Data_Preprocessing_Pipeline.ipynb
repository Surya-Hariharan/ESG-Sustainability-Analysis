{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4d2640fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn.covariance import MinCovDet\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b5cdc7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÖ Data preprocessing started on: 2026-01-28 23:39:45\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "np.random.seed(42)\n",
    "print(f\"üìÖ Data preprocessing started on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6a63f722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _safe_numeric_frame(df_in, cols):\n",
    "    X = df_in[cols].copy()\n",
    "    X = X.replace([np.inf, -np.inf], np.nan)\n",
    "    for c in cols:\n",
    "        X[c] = pd.to_numeric(X[c], errors='coerce')\n",
    "    X = X.fillna(X.median(numeric_only=True))\n",
    "    return X\n",
    "\n",
    "def psi_numeric(expected, actual, bins=10):\n",
    "    expected = pd.Series(expected).dropna().astype(float)\n",
    "    actual = pd.Series(actual).dropna().astype(float)\n",
    "    if len(expected) < 2 or len(actual) < 2:\n",
    "        return np.nan\n",
    "    quantiles = np.linspace(0, 1, bins + 1)\n",
    "    edges = expected.quantile(quantiles).values\n",
    "    edges = np.unique(edges)\n",
    "    if len(edges) < 3:\n",
    "        return np.nan\n",
    "    expected_bins = pd.cut(expected, bins=edges, include_lowest=True)\n",
    "    actual_bins = pd.cut(actual, bins=edges, include_lowest=True)\n",
    "    expected_dist = expected_bins.value_counts(normalize=True).sort_index()\n",
    "    actual_dist = actual_bins.value_counts(normalize=True).sort_index()\n",
    "    eps = 1e-12\n",
    "    expected_dist = expected_dist.clip(eps, 1)\n",
    "    actual_dist = actual_dist.clip(eps, 1)\n",
    "    return float(((actual_dist - expected_dist) * np.log(actual_dist / expected_dist)).sum())\n",
    "\n",
    "def correlation_prune(df_in, cols, threshold=0.95):\n",
    "    X = df_in[cols].copy()\n",
    "    X = X.replace([np.inf, -np.inf], np.nan)\n",
    "    X = X.fillna(X.median(numeric_only=True))\n",
    "    corr = X.corr().abs()\n",
    "    upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "    drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "    return drop\n",
    "\n",
    "def compute_vif(df_in, cols, max_features=40):\n",
    "    cols = [c for c in cols if c in df_in.columns]\n",
    "    cols = [c for c in cols if pd.api.types.is_numeric_dtype(df_in[c])]\n",
    "    if len(cols) < 2:\n",
    "        return pd.DataFrame(columns=['feature', 'vif'])\n",
    "    if len(cols) > max_features:\n",
    "        variances = df_in[cols].var().sort_values(ascending=False)\n",
    "        cols = list(variances.head(max_features).index)\n",
    "    X = df_in[cols].copy()\n",
    "    X = X.replace([np.inf, -np.inf], np.nan)\n",
    "    X = X.fillna(X.median(numeric_only=True))\n",
    "    X = (X - X.mean()) / (X.std(ddof=0) + 1e-12)\n",
    "    vifs = []\n",
    "    X_np = X.values\n",
    "    for i, feature in enumerate(cols):\n",
    "        y = X_np[:, i]\n",
    "        X_other = np.delete(X_np, i, axis=1)\n",
    "        if X_other.shape[1] == 0:\n",
    "            vifs.append((feature, 1.0))\n",
    "            continue\n",
    "        beta, *_ = np.linalg.lstsq(X_other, y, rcond=None)\n",
    "        y_hat = X_other @ beta\n",
    "        ss_res = float(np.sum((y - y_hat) ** 2))\n",
    "        ss_tot = float(np.sum((y - np.mean(y)) ** 2))\n",
    "        r2 = 1 - ss_res / (ss_tot + 1e-12)\n",
    "        vif = 1.0 / (1.0 - r2 + 1e-12)\n",
    "        vifs.append((feature, float(vif)))\n",
    "    return pd.DataFrame(vifs, columns=['feature', 'vif']).sort_values('vif', ascending=False).reset_index(drop=True)\n",
    "\n",
    "def mahalanobis_distance(df_in, cols, random_state=42):\n",
    "    X = _safe_numeric_frame(df_in, cols)\n",
    "    if X.shape[1] < 2 or X.shape[0] < 5:\n",
    "        return pd.Series(np.nan, index=df_in.index)\n",
    "    try:\n",
    "        mcd = MinCovDet(random_state=random_state, support_fraction=None)\n",
    "        mcd.fit(X.values)\n",
    "        diff = X.values - mcd.location_\n",
    "        inv_cov = np.linalg.inv(mcd.covariance_)\n",
    "        d2 = np.einsum('ij,jk,ik->i', diff, inv_cov, diff)\n",
    "        return pd.Series(np.sqrt(np.maximum(d2, 0)), index=df_in.index)\n",
    "    except Exception:\n",
    "        cov = np.cov(X.values, rowvar=False)\n",
    "        cov = cov + np.eye(cov.shape[0]) * 1e-9\n",
    "        inv_cov = np.linalg.inv(cov)\n",
    "        diff = X.values - np.mean(X.values, axis=0)\n",
    "        d2 = np.einsum('ij,jk,ik->i', diff, inv_cov, diff)\n",
    "        return pd.Series(np.sqrt(np.maximum(d2, 0)), index=df_in.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4d5e0322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Raw dataset loaded successfully!\n",
      "üìä Original dataset shape: 503 rows √ó 15 columns\n",
      "üíæ Memory usage: 1.04 MB\n",
      "\n",
      "üîÑ Working copy created for preprocessing\n"
     ]
    }
   ],
   "source": [
    "data_path = '../data/raw/dataset.csv'\n",
    "output_path = '../data/processed/'\n",
    "try:\n",
    "    df_raw = pd.read_csv(data_path)\n",
    "    print(\"‚úÖ Raw dataset loaded successfully!\")\n",
    "    print(f\"üìä Original dataset shape: {df_raw.shape[0]:,} rows √ó {df_raw.shape[1]} columns\")\n",
    "    print(f\"üíæ Memory usage: {df_raw.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Dataset file not found. Please check the file path.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading dataset: {e}\")\n",
    "df = df_raw.copy()\n",
    "print(f\"\\nüîÑ Working copy created for preprocessing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "726587d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç INITIAL DATA ASSESSMENT\n",
      "==================================================\n",
      "Dataset Shape: (503, 15)\n",
      "\n",
      "Column Information:\n",
      " 1. Symbol                    | Missing:   0 (  0.0%)\n",
      " 2. Name                      | Missing:   0 (  0.0%)\n",
      " 3. Address                   | Missing:   1 (  0.2%)\n",
      " 4. Sector                    | Missing:   1 (  0.2%)\n",
      " 5. Industry                  | Missing:   1 (  0.2%)\n",
      " 6. Full Time Employees       | Missing:   5 (  1.0%)\n",
      " 7. Description               | Missing:   1 (  0.2%)\n",
      " 8. Total ESG Risk score      | Missing:  73 ( 14.5%)\n",
      " 9. Environment Risk Score    | Missing:  73 ( 14.5%)\n",
      "10. Governance Risk Score     | Missing:  73 ( 14.5%)\n",
      "11. Social Risk Score         | Missing:  73 ( 14.5%)\n",
      "12. Controversy Level         | Missing:  73 ( 14.5%)\n",
      "13. Controversy Score         | Missing: 100 ( 19.9%)\n",
      "14. ESG Risk Percentile       | Missing:  73 ( 14.5%)\n",
      "15. ESG Risk Level            | Missing:  73 ( 14.5%)\n",
      "\n",
      "üìä Total Missing Values: 620\n",
      "üìä Data Completeness: 91.8%\n"
     ]
    }
   ],
   "source": [
    "print(\"üîç INITIAL DATA ASSESSMENT\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"\\nColumn Information:\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    missing_count = df[col].isnull().sum()\n",
    "    missing_pct = (missing_count / len(df)) * 100\n",
    "    print(f\"{i:2d}. {col:<25} | Missing: {missing_count:3d} ({missing_pct:5.1f}%)\")\n",
    "print(f\"\\nüìä Total Missing Values: {df.isnull().sum().sum():,}\")\n",
    "print(f\"üìä Data Completeness: {((df.shape[0] * df.shape[1] - df.isnull().sum().sum()) / (df.shape[0] * df.shape[1]) * 100):.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7f515195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ STEP 1: BASIC DATA CLEANING\n",
      "========================================\n",
      "Duplicate rows found: 0\n",
      "\n",
      "üìã Company Symbol Analysis:\n",
      "Duplicate symbols: 0\n",
      "‚úÖ All company symbols are unique\n",
      "\n",
      "üìä Shape after basic cleaning: (503, 15) (removed 0 rows)\n"
     ]
    }
   ],
   "source": [
    "print(\"üßπ STEP 1: BASIC DATA CLEANING\")\n",
    "print(\"=\" * 40)\n",
    "initial_shape = df.shape\n",
    "duplicate_rows = df.duplicated().sum()\n",
    "print(f\"Duplicate rows found: {duplicate_rows}\")\n",
    "if duplicate_rows > 0:\n",
    "    df = df.drop_duplicates()\n",
    "    print(f\"‚úÖ Removed {duplicate_rows} duplicate rows\")\n",
    "print(f\"\\nüìã Company Symbol Analysis:\")\n",
    "if 'Symbol' in df.columns:\n",
    "    duplicate_symbols = df['Symbol'].duplicated().sum()\n",
    "    print(f\"Duplicate symbols: {duplicate_symbols}\")\n",
    "    if duplicate_symbols > 0:\n",
    "        print(\"üîç Duplicate symbols found:\")\n",
    "        duplicated_syms = df[df['Symbol'].duplicated(keep=False)]['Symbol'].value_counts()\n",
    "        print(duplicated_syms)\n",
    "    else:\n",
    "        print(\"‚úÖ All company symbols are unique\")\n",
    "print(f\"\\nüìä Shape after basic cleaning: {df.shape} (removed {initial_shape[0] - df.shape[0]} rows)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bbab5bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ STEP 2: EMPLOYEE DATA STANDARDIZATION\n",
      "=============================================\n",
      "Processing employee count data...\n",
      "Original data type: object\n",
      "‚úÖ Employee data standardized:\n",
      "   Valid records: 498/503\n",
      "   Range: 28 to 2,100,000\n",
      "   Median: 21,585\n",
      "\n",
      "‚ö†Ô∏è  Large companies (>1M employees):\n",
      "   WMT: 2,100,000 employees\n",
      "   AMZN: 1,525,000 employees\n"
     ]
    }
   ],
   "source": [
    "print(\"üßπ STEP 2: EMPLOYEE DATA STANDARDIZATION\")\n",
    "print(\"=\" * 45)\n",
    "if 'Full Time Employees' in df.columns:\n",
    "    print(\"Processing employee count data...\")\n",
    "    print(f\"Original data type: {df['Full Time Employees'].dtype}\")\n",
    "    \n",
    "    def clean_employee_count(value):\n",
    "        if pd.isna(value):\n",
    "            return np.nan\n",
    "        if isinstance(value, (int, float)):\n",
    "            return float(value)\n",
    "        \n",
    "        value_str = str(value).strip()\n",
    "        if value_str == '' or value_str.lower() in ['nan', 'null', 'none']:\n",
    "            return np.nan\n",
    "        \n",
    "        value_clean = re.sub(r'[^0-9.]', '', value_str)\n",
    "        try:\n",
    "            return float(value_clean)\n",
    "        except:\n",
    "            return np.nan\n",
    "    \n",
    "    df['Full Time Employees'] = df['Full Time Employees'].apply(clean_employee_count)\n",
    "    \n",
    "    employee_stats = df['Full Time Employees'].describe()\n",
    "    print(f\"‚úÖ Employee data standardized:\")\n",
    "    print(f\"   Valid records: {df['Full Time Employees'].count()}/{len(df)}\")\n",
    "    print(f\"   Range: {employee_stats['min']:,.0f} to {employee_stats['max']:,.0f}\")\n",
    "    print(f\"   Median: {employee_stats['50%']:,.0f}\")\n",
    "    \n",
    "    extreme_outliers = df['Full Time Employees'] > 1000000\n",
    "    if extreme_outliers.any():\n",
    "        print(f\"\\n‚ö†Ô∏è  Large companies (>1M employees):\")\n",
    "        large_companies = df[extreme_outliers][['Symbol', 'Name', 'Full Time Employees']]\n",
    "        for _, row in large_companies.iterrows():\n",
    "            print(f\"   {row['Symbol']}: {row['Full Time Employees']:,.0f} employees\")\n",
    "else:\n",
    "    print(\"‚ùå 'Full Time Employees' column not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ccb06964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ STEP 3: ESG RISK SCORES PREPROCESSING\n",
      "=============================================\n",
      "üéØ Identified 5 ESG-related numeric columns:\n",
      "   1. Total ESG Risk score\n",
      "   2. Environment Risk Score\n",
      "   3. Governance Risk Score\n",
      "   4. Social Risk Score\n",
      "   5. Controversy Score\n",
      "\n",
      "üìä ESG Data Completeness Analysis:\n",
      "   Total ESG Risk score     : 430/503 valid ( 85.5%)\n",
      "   Environment Risk Score   : 430/503 valid ( 85.5%)\n",
      "   Governance Risk Score    : 430/503 valid ( 85.5%)\n",
      "   Social Risk Score        : 430/503 valid ( 85.5%)\n",
      "   Controversy Score        : 403/503 valid ( 80.1%)\n",
      "\n",
      "üîç ESG Score Ranges:\n",
      "   Total ESG Risk score     :    7.1 -   41.7 (mean:   21.5)\n",
      "   Environment Risk Score   :    0.0 -   25.0 (mean:    5.7)\n",
      "   Governance Risk Score    :    3.0 -   19.4 (mean:    6.7)\n",
      "   Social Risk Score        :    0.8 -   22.5 (mean:    9.1)\n",
      "   Controversy Score        :    1.0 -    5.0 (mean:    2.0)\n"
     ]
    }
   ],
   "source": [
    "print(\"üßπ STEP 3: ESG RISK SCORES PREPROCESSING\")\n",
    "print(\"=\" * 45)\n",
    "esg_columns = []\n",
    "for col in df.columns:\n",
    "    if any(keyword in col.lower() for keyword in ['esg', 'risk', 'score', 'environment', 'social', 'governance']):\n",
    "        if df[col].dtype in ['int64', 'float64'] or col in ['Total ESG Risk score', 'Environment Risk Score', 'Governance Risk Score', 'Social Risk Score', 'Controversy Score']:\n",
    "            esg_columns.append(col)\n",
    "print(f\"üéØ Identified {len(esg_columns)} ESG-related numeric columns:\")\n",
    "for i, col in enumerate(esg_columns, 1):\n",
    "    print(f\"   {i}. {col}\")\n",
    "if esg_columns:\n",
    "    print(f\"\\nüìä ESG Data Completeness Analysis:\")\n",
    "    for col in esg_columns:\n",
    "        valid_count = df[col].count()\n",
    "        missing_count = df[col].isnull().sum()\n",
    "        missing_pct = (missing_count / len(df)) * 100\n",
    "        print(f\"   {col:<25}: {valid_count:3d}/{len(df)} valid ({100-missing_pct:5.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nüîç ESG Score Ranges:\")\n",
    "    for col in esg_columns:\n",
    "        if df[col].count() > 0:\n",
    "            min_val = df[col].min()\n",
    "            max_val = df[col].max()\n",
    "            mean_val = df[col].mean()\n",
    "            print(f\"   {col:<25}: {min_val:6.1f} - {max_val:6.1f} (mean: {mean_val:6.1f})\")\n",
    "else:\n",
    "    print(\"‚ùå No ESG columns identified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "07e73d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ STEP 4: CATEGORICAL DATA STANDARDIZATION\n",
      "=============================================\n",
      "\n",
      "üìä Processing Sector:\n",
      "   Unique values: 12 (including NaN)\n",
      "   Missing: 1 (0.2%)\n",
      "   Top 5 categories: ['Technology', 'Industrials', 'Financial Services', 'Healthcare', 'Consumer Cyclical']\n",
      "\n",
      "üìä Processing Industry:\n",
      "   Unique values: 117 (including NaN)\n",
      "   Missing: 1 (0.2%)\n",
      "   Top 5 categories: ['Utilities - Regulated Electric', 'Specialty Industrial Machinery', 'Semiconductors', 'Software - Application', 'Aerospace & Defense']\n",
      "\n",
      "üìä Processing Controversy Level:\n",
      "   Unique values: 7 (including NaN)\n",
      "   Missing: 73 (14.5%)\n",
      "   Top categories: ['Moderate Controversy Level', 'Low Controversy Level', 'Significant Controversy Level', nan, 'None Controversy Level']\n",
      "\n",
      "üìä Processing ESG Risk Level:\n",
      "   Unique values: 6 (including NaN)\n",
      "   Missing: 73 (14.5%)\n",
      "   Top categories: ['Low', 'Medium', nan, 'High', 'Negligible']\n",
      "\n",
      "üìä Processing ESG Risk Percentile:\n",
      "   Unique values: 90 (including NaN)\n",
      "   Missing: 73 (14.5%)\n",
      "   Sample values: [nan, '16th percentile', '23rd percentile', '9th percentile', '6th percentile']\n",
      "   ‚úÖ Created numeric percentile column: 1-93 range\n"
     ]
    }
   ],
   "source": [
    "print(\"üßπ STEP 4: CATEGORICAL DATA STANDARDIZATION\")\n",
    "print(\"=\" * 45)\n",
    "categorical_columns = ['Sector', 'Industry', 'Controversy Level', 'ESG Risk Level', 'ESG Risk Percentile']\n",
    "for col in categorical_columns:\n",
    "    if col in df.columns:\n",
    "        print(f\"\\nüìä Processing {col}:\")\n",
    "        \n",
    "        df[col] = df[col].astype(str).str.strip()\n",
    "        df[col] = df[col].replace(['nan', 'None', 'null', ''], np.nan)\n",
    "        \n",
    "        unique_values = df[col].value_counts(dropna=False)\n",
    "        print(f\"   Unique values: {len(unique_values)} (including NaN)\")\n",
    "        print(f\"   Missing: {df[col].isnull().sum()} ({(df[col].isnull().sum()/len(df)*100):.1f}%)\")\n",
    "        \n",
    "        if col == 'ESG Risk Percentile':\n",
    "            print(f\"   Sample values: {list(unique_values.head().index)}\")\n",
    "            \n",
    "            def extract_percentile_number(value):\n",
    "                if pd.isna(value) or value == 'nan':\n",
    "                    return np.nan\n",
    "                try:\n",
    "                    percentile_match = re.search(r'(\\d+)', str(value))\n",
    "                    if percentile_match:\n",
    "                        return int(percentile_match.group(1))\n",
    "                    return np.nan\n",
    "                except:\n",
    "                    return np.nan\n",
    "            \n",
    "            df['ESG_Risk_Percentile_Numeric'] = df[col].apply(extract_percentile_number)\n",
    "            valid_percentiles = df['ESG_Risk_Percentile_Numeric'].dropna()\n",
    "            if len(valid_percentiles) > 0:\n",
    "                print(f\"   ‚úÖ Created numeric percentile column: {valid_percentiles.min():.0f}-{valid_percentiles.max():.0f} range\")\n",
    "        \n",
    "        elif col in ['Controversy Level', 'ESG Risk Level']:\n",
    "            print(f\"   Top categories: {list(unique_values.head().index)}\")\n",
    "        \n",
    "        elif col in ['Sector', 'Industry']:\n",
    "            print(f\"   Top 5 categories: {list(unique_values.head().index)}\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå {col} not found in dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "81be6f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ STEP 5: MISSING VALUE TREATMENT STRATEGY\n",
      "==================================================\n",
      "üìä Missing Value Categories:\n",
      "   üî¥ High missing (>10%): 9 columns\n",
      "   üü° Medium missing (1-10%): 0 columns\n",
      "   üü¢ Low missing (<1%): 5 columns\n",
      "\n",
      "üî¥ High Missing Columns:\n",
      "   Controversy Score        :  19.9% missing\n",
      "   Total ESG Risk score     :  14.5% missing\n",
      "   Environment Risk Score   :  14.5% missing\n",
      "   Governance Risk Score    :  14.5% missing\n",
      "   Social Risk Score        :  14.5% missing\n",
      "   Controversy Level        :  14.5% missing\n",
      "   ESG Risk Percentile      :  14.5% missing\n",
      "   ESG Risk Level           :  14.5% missing\n",
      "   ESG_Risk_Percentile_Numeric:  14.5% missing\n",
      "\n",
      "üìã Imputation Strategy Summary:\n",
      "   forward_fill: 5 columns\n",
      "   knn_imputation: 5 columns\n",
      "   median_mode: 4 columns\n",
      "   no_action: 2 columns\n"
     ]
    }
   ],
   "source": [
    "print(\"üßπ STEP 5: MISSING VALUE TREATMENT STRATEGY\")\n",
    "print(\"=\" * 50)\n",
    "missing_analysis = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing_Count': df.isnull().sum(),\n",
    "    'Missing_Percentage': (df.isnull().sum() / len(df)) * 100,\n",
    "    'Data_Type': df.dtypes\n",
    "}).sort_values('Missing_Percentage', ascending=False)\n",
    "high_missing = missing_analysis[missing_analysis['Missing_Percentage'] > 10]\n",
    "medium_missing = missing_analysis[(missing_analysis['Missing_Percentage'] > 1) & (missing_analysis['Missing_Percentage'] <= 10)]\n",
    "low_missing = missing_analysis[(missing_analysis['Missing_Percentage'] > 0) & (missing_analysis['Missing_Percentage'] <= 1)]\n",
    "print(f\"üìä Missing Value Categories:\")\n",
    "print(f\"   üî¥ High missing (>10%): {len(high_missing)} columns\")\n",
    "print(f\"   üü° Medium missing (1-10%): {len(medium_missing)} columns\")\n",
    "print(f\"   üü¢ Low missing (<1%): {len(low_missing)} columns\")\n",
    "if len(high_missing) > 0:\n",
    "    print(f\"\\nüî¥ High Missing Columns:\")\n",
    "    for _, row in high_missing.iterrows():\n",
    "        print(f\"   {row['Column']:<25}: {row['Missing_Percentage']:5.1f}% missing\")\n",
    "imputation_strategy = {}\n",
    "for col in df.columns:\n",
    "    missing_pct = (df[col].isnull().sum() / len(df)) * 100\n",
    "    \n",
    "    if missing_pct == 0:\n",
    "        imputation_strategy[col] = 'no_action'\n",
    "    elif missing_pct > 25:\n",
    "        imputation_strategy[col] = 'flag_and_median'\n",
    "    elif missing_pct > 10:\n",
    "        if col in esg_columns:\n",
    "            imputation_strategy[col] = 'knn_imputation'\n",
    "        else:\n",
    "            imputation_strategy[col] = 'median_mode'\n",
    "    elif missing_pct > 1:\n",
    "        imputation_strategy[col] = 'median_mode'\n",
    "    else:\n",
    "        imputation_strategy[col] = 'forward_fill'\n",
    "print(f\"\\nüìã Imputation Strategy Summary:\")\n",
    "strategy_counts = pd.Series(list(imputation_strategy.values())).value_counts()\n",
    "for strategy, count in strategy_counts.items():\n",
    "    print(f\"   {strategy}: {count} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f049d285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing_env_flag=1: 73\n",
      "missing_social_flag=1: 73\n",
      "missing_gov_flag=1: 73\n"
     ]
    }
   ],
   "source": [
    "missingness_original = df.isna()\n",
    "env_cols = [c for c in df.columns if any(k in c.lower() for k in ['environment']) and pd.api.types.is_numeric_dtype(df[c])]\n",
    "social_cols = [c for c in df.columns if any(k in c.lower() for k in ['social']) and pd.api.types.is_numeric_dtype(df[c])]\n",
    "gov_cols = [c for c in df.columns if any(k in c.lower() for k in ['governance']) and pd.api.types.is_numeric_dtype(df[c])]\n",
    "if 'Environment Risk Score' in df.columns and 'Environment Risk Score' not in env_cols and pd.api.types.is_numeric_dtype(df['Environment Risk Score']):\n",
    "    env_cols.append('Environment Risk Score')\n",
    "if 'Social Risk Score' in df.columns and 'Social Risk Score' not in social_cols and pd.api.types.is_numeric_dtype(df['Social Risk Score']):\n",
    "    social_cols.append('Social Risk Score')\n",
    "if 'Governance Risk Score' in df.columns and 'Governance Risk Score' not in gov_cols and pd.api.types.is_numeric_dtype(df['Governance Risk Score']):\n",
    "    gov_cols.append('Governance Risk Score')\n",
    "missing_env_flag = (df[env_cols].isna().any(axis=1).astype(int) if len(env_cols) > 0 else pd.Series(0, index=df.index))\n",
    "missing_social_flag = (df[social_cols].isna().any(axis=1).astype(int) if len(social_cols) > 0 else pd.Series(0, index=df.index))\n",
    "missing_gov_flag = (df[gov_cols].isna().any(axis=1).astype(int) if len(gov_cols) > 0 else pd.Series(0, index=df.index))\n",
    "print(f\"missing_env_flag=1: {int(missing_env_flag.sum())}\")\n",
    "print(f\"missing_social_flag=1: {int(missing_social_flag.sum())}\")\n",
    "print(f\"missing_gov_flag=1: {int(missing_gov_flag.sum())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dcd4c196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß STEP 6: IMPLEMENTING MISSING VALUE IMPUTATION\n",
      "==================================================\n",
      "   Address                       :   1 ‚Üí   0 missing (forward_fill)\n",
      "   Sector                        :   1 ‚Üí   0 missing (forward_fill)\n",
      "   Industry                      :   1 ‚Üí   0 missing (forward_fill)\n",
      "   Full Time Employees           :   5 ‚Üí   0 missing (forward_fill)\n",
      "   Description                   :   1 ‚Üí   0 missing (forward_fill)\n",
      "   Total ESG Risk score          :  73 ‚Üí   0 missing (knn_imputation)\n",
      "   Environment Risk Score        :  73 ‚Üí   0 missing (knn_imputation)\n",
      "   Governance Risk Score         :  73 ‚Üí   0 missing (knn_imputation)\n",
      "   Social Risk Score             :  73 ‚Üí   0 missing (knn_imputation)\n",
      "   Controversy Level             :  73 ‚Üí   0 missing (median_mode)\n",
      "   Controversy Score             : 100 ‚Üí   0 missing (knn_imputation)\n",
      "   ESG Risk Percentile           :  73 ‚Üí   0 missing (median_mode)\n",
      "   ESG Risk Level                :  73 ‚Üí   0 missing (median_mode)\n",
      "   ESG_Risk_Percentile_Numeric   :  73 ‚Üí   0 missing (median_mode)\n",
      "\n",
      "‚úÖ Imputation completed!\n",
      "üìä Total missing values: 693 ‚Üí 0\n",
      "üìä Data completeness: 100.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"üîß STEP 6: IMPLEMENTING MISSING VALUE IMPUTATION\")\n",
    "print(\"=\" * 50)\n",
    "df_imputed = df.copy()\n",
    "for col, strategy in imputation_strategy.items():\n",
    "    if strategy == 'no_action':\n",
    "        continue\n",
    "    \n",
    "    missing_before = df_imputed[col].isnull().sum()\n",
    "    \n",
    "    if strategy == 'forward_fill':\n",
    "        if df_imputed[col].dtype in ['object']:\n",
    "            df_imputed[col].fillna(method='ffill', inplace=True)\n",
    "            df_imputed[col].fillna('Unknown', inplace=True)\n",
    "        else:\n",
    "            df_imputed[col].fillna(df_imputed[col].median(), inplace=True)\n",
    "    \n",
    "    elif strategy == 'median_mode':\n",
    "        if df_imputed[col].dtype in ['object']:\n",
    "            mode_val = df_imputed[col].mode()\n",
    "            fill_val = mode_val.iloc[0] if len(mode_val) > 0 else 'Unknown'\n",
    "            df_imputed[col].fillna(fill_val, inplace=True)\n",
    "        else:\n",
    "            df_imputed[col].fillna(df_imputed[col].median(), inplace=True)\n",
    "    \n",
    "    elif strategy == 'flag_and_median':\n",
    "        df_imputed[f'{col}_was_missing'] = df_imputed[col].isnull().astype(int)\n",
    "        if df_imputed[col].dtype in ['object']:\n",
    "            mode_val = df_imputed[col].mode()\n",
    "            fill_val = mode_val.iloc[0] if len(mode_val) > 0 else 'Unknown'\n",
    "            df_imputed[col].fillna(fill_val, inplace=True)\n",
    "        else:\n",
    "            df_imputed[col].fillna(df_imputed[col].median(), inplace=True)\n",
    "    \n",
    "    elif strategy == 'knn_imputation' and col in esg_columns:\n",
    "        if df_imputed[col].count() > 0:\n",
    "            esg_subset = df_imputed[esg_columns].select_dtypes(include=[np.number])\n",
    "            if esg_subset.shape[1] > 1:\n",
    "                try:\n",
    "                    imputer = KNNImputer(n_neighbors=5)\n",
    "                    esg_imputed = imputer.fit_transform(esg_subset)\n",
    "                    \n",
    "                    col_idx = esg_subset.columns.get_loc(col)\n",
    "                    df_imputed[col] = esg_imputed[:, col_idx]\n",
    "                except:\n",
    "                    df_imputed[col].fillna(df_imputed[col].median(), inplace=True)\n",
    "            else:\n",
    "                df_imputed[col].fillna(df_imputed[col].median(), inplace=True)\n",
    "    \n",
    "    missing_after = df_imputed[col].isnull().sum()\n",
    "    \n",
    "    if missing_before > 0:\n",
    "        print(f\"   {col:<30}: {missing_before:3d} ‚Üí {missing_after:3d} missing ({strategy})\")\n",
    "\n",
    "print(f\"\\n‚úÖ Imputation completed!\")\n",
    "print(f\"üìä Total missing values: {df.isnull().sum().sum()} ‚Üí {df_imputed.isnull().sum().sum()}\")\n",
    "print(f\"üìä Data completeness: {((df_imputed.shape[0] * df_imputed.shape[1] - df_imputed.isnull().sum().sum()) / (df_imputed.shape[0] * df_imputed.shape[1]) * 100):.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7f7a3698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean imputed_fraction: 0.0725\n",
      "Rows with any imputation: 103\n"
     ]
    }
   ],
   "source": [
    "df_imputed['missing_env_flag'] = missing_env_flag.values\n",
    "df_imputed['missing_social_flag'] = missing_social_flag.values\n",
    "df_imputed['missing_gov_flag'] = missing_gov_flag.values\n",
    "imputed_mask = missingness_original.reindex(df_imputed.index, columns=df_imputed.columns, fill_value=False)\n",
    "common_cols = [c for c in imputed_mask.columns if c in df_imputed.columns]\n",
    "imputed_fraction = imputed_mask[common_cols].mean(axis=1)\n",
    "df_imputed['imputed_fraction'] = imputed_fraction.values\n",
    "if 'Full Time Employees' in df_imputed.columns:\n",
    "    employees_before_univariate = df_imputed['Full Time Employees'].copy()\n",
    "else:\n",
    "    employees_before_univariate = None\n",
    "print(f\"Mean imputed_fraction: {df_imputed['imputed_fraction'].mean():.4f}\")\n",
    "print(f\"Rows with any imputation: {int((df_imputed['imputed_fraction'] > 0).sum())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b5ffefc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß STEP 7: OUTLIER DETECTION AND TREATMENT\n",
      "=============================================\n",
      "üìä Outlier Analysis:\n",
      "   Controversy Score             : 218 outliers (43.3%)\n",
      "   Full Time Employees           :  52 outliers (10.3%)\n",
      "   Governance Risk Score         :  19 outliers ( 3.8%)\n",
      "   Social Risk Score             :  18 outliers ( 3.6%)\n",
      "   Environment Risk Score        :   9 outliers ( 1.8%)\n",
      "   Total ESG Risk score          :   7 outliers ( 1.4%)\n",
      "\n",
      "üéØ Outlier Treatment Strategy:\n",
      "   Full Time Employees: Capped 6 values at 99th percentile (439,500)\n",
      "   Controversy Score: Keeping 218 outliers (legitimate ESG risk variation)\n",
      "\n",
      "‚úÖ Outlier treatment completed!\n"
     ]
    }
   ],
   "source": [
    "print(\"üîß STEP 7: OUTLIER DETECTION AND TREATMENT\")\n",
    "print(\"=\" * 45)\n",
    "numeric_columns = df_imputed.select_dtypes(include=[np.number]).columns\n",
    "exclude_outlier_cols = [c for c in numeric_columns if str(c).endswith('_flag') or str(c).endswith('_was_missing') or str(c) in ['imputed_fraction', 'univariate_outlier_count', 'univariate_outlier_fraction']]\n",
    "numeric_columns = [c for c in numeric_columns if c not in exclude_outlier_cols]\n",
    "outlier_summary = []\n",
    "for col in numeric_columns:\n",
    "    if df_imputed[col].count() > 0:\n",
    "        Q1 = df_imputed[col].quantile(0.25)\n",
    "        Q3 = df_imputed[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        outliers = df_imputed[(df_imputed[col] < lower_bound) | (df_imputed[col] > upper_bound)]\n",
    "        outlier_count = len(outliers)\n",
    "        outlier_percentage = (outlier_count / len(df_imputed)) * 100\n",
    "        outlier_summary.append({\n",
    "            'Column': col,\n",
    "            'Outliers': outlier_count,\n",
    "            'Percentage': outlier_percentage,\n",
    "            'Lower_Bound': lower_bound,\n",
    "            'Upper_Bound': upper_bound\n",
    "        })\n",
    "outlier_df = pd.DataFrame(outlier_summary)\n",
    "outlier_df = outlier_df.sort_values('Percentage', ascending=False)\n",
    "print(\"üìä Outlier Analysis:\")\n",
    "for _, row in outlier_df.head(10).iterrows():\n",
    "    if row['Outliers'] > 0:\n",
    "        print(f\"   {row['Column']:<30}: {row['Outliers']:3d} outliers ({row['Percentage']:4.1f}%)\")\n",
    "print(f\"\\nüéØ Outlier Treatment Strategy:\")\n",
    "for col in numeric_columns:\n",
    "    if col in outlier_df[outlier_df['Percentage'] > 5]['Column'].values:\n",
    "        if 'Employee' in col:\n",
    "            cap_value = df_imputed[col].quantile(0.99)\n",
    "            outlier_count = (df_imputed[col] > cap_value).sum()\n",
    "            df_imputed[col] = np.where(df_imputed[col] > cap_value, cap_value, df_imputed[col])\n",
    "            print(f\"   {col}: Capped {outlier_count} values at 99th percentile ({cap_value:,.0f})\")\n",
    "        elif col in esg_columns:\n",
    "            outlier_count = len(outlier_df[outlier_df['Column'] == col])\n",
    "            if outlier_count > 0:\n",
    "                print(f\"   {col}: Keeping {outlier_df[outlier_df['Column']==col]['Outliers'].iloc[0]} outliers (legitimate ESG risk variation)\")\n",
    "        else:\n",
    "            outlier_info = outlier_df[outlier_df['Column'] == col].iloc[0]\n",
    "            if outlier_info['Outliers'] > 0:\n",
    "                print(f\"   {col}: Flagged {outlier_info['Outliers']} outliers for review\")\n",
    "print(f\"\\n‚úÖ Outlier treatment completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c4747d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean univariate_outlier_count: 0.642\n",
      "Rows with any univariate outlier: 254\n"
     ]
    }
   ],
   "source": [
    "numeric_columns_for_outliers = df_imputed.select_dtypes(include=[np.number]).columns\n",
    "bounds = {}\n",
    "for _, r in outlier_df.iterrows():\n",
    "    bounds[r['Column']] = (float(r['Lower_Bound']), float(r['Upper_Bound']))\n",
    "univariate_outlier_count = pd.Series(0, index=df_imputed.index, dtype=int)\n",
    "for c in numeric_columns_for_outliers:\n",
    "    if c in bounds:\n",
    "        lb, ub = bounds[c]\n",
    "        v = df_imputed[c]\n",
    "        o = (v < lb) | (v > ub)\n",
    "        univariate_outlier_count = univariate_outlier_count + o.fillna(False).astype(int)\n",
    "df_imputed['univariate_outlier_count'] = univariate_outlier_count.values\n",
    "df_imputed['univariate_outlier_fraction'] = (df_imputed['univariate_outlier_count'] / max(1, len(bounds))).astype(float)\n",
    "print(f\"Mean univariate_outlier_count: {df_imputed['univariate_outlier_count'].mean():.3f}\")\n",
    "print(f\"Rows with any univariate outlier: {int((df_imputed['univariate_outlier_count'] > 0).sum())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bcf7b324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv_outlier_flag=1: 28\n",
      "Mean data_confidence: 0.6505\n",
      "Low-confidence (<0.7): 326\n"
     ]
    }
   ],
   "source": [
    "multivar_cols = [c for c in df_imputed.select_dtypes(include=[np.number]).columns if c not in ['univariate_outlier_count', 'univariate_outlier_fraction']]\n",
    "multivar_cols = [c for c in multivar_cols if not str(c).endswith('_was_missing')]\n",
    "X_mv = _safe_numeric_frame(df_imputed, multivar_cols)\n",
    "if X_mv.shape[1] >= 2 and X_mv.shape[0] >= 10:\n",
    "    iso = IsolationForest(n_estimators=300, contamination='auto', random_state=42)\n",
    "    iso.fit(X_mv.values)\n",
    "    iso_score = -iso.score_samples(X_mv.values)\n",
    "    df_imputed['mv_isolation_forest_score'] = iso_score\n",
    "    lof = LocalOutlierFactor(n_neighbors=min(35, max(5, int(np.sqrt(X_mv.shape[0])))), contamination='auto')\n",
    "    lof_fit = lof.fit_predict(X_mv.values)\n",
    "    lof_score = -lof.negative_outlier_factor_\n",
    "    df_imputed['mv_lof_score'] = lof_score\n",
    "    df_imputed['mv_mahalanobis'] = mahalanobis_distance(df_imputed, multivar_cols).values\n",
    "    iso_thr = float(np.nanquantile(df_imputed['mv_isolation_forest_score'], 0.98))\n",
    "    lof_thr = float(np.nanquantile(df_imputed['mv_lof_score'], 0.98))\n",
    "    mah_thr = float(np.nanquantile(df_imputed['mv_mahalanobis'], 0.98))\n",
    "    df_imputed['mv_outlier_flag'] = ((df_imputed['mv_isolation_forest_score'] >= iso_thr) | (df_imputed['mv_lof_score'] >= lof_thr) | (df_imputed['mv_mahalanobis'] >= mah_thr)).astype(int)\n",
    "else:\n",
    "    df_imputed['mv_isolation_forest_score'] = np.nan\n",
    "    df_imputed['mv_lof_score'] = np.nan\n",
    "    df_imputed['mv_mahalanobis'] = np.nan\n",
    "    df_imputed['mv_outlier_flag'] = 0\n",
    "outlier_penalty = 0.5 * df_imputed['mv_outlier_flag'].astype(float) + 0.5 * (df_imputed['univariate_outlier_count'] > 0).astype(float)\n",
    "df_imputed['data_confidence'] = (1.0 - (df_imputed['imputed_fraction'].astype(float) + outlier_penalty)).clip(0, 1)\n",
    "print(f\"mv_outlier_flag=1: {int(df_imputed['mv_outlier_flag'].sum())}\")\n",
    "print(f\"Mean data_confidence: {df_imputed['data_confidence'].mean():.4f}\")\n",
    "print(f\"Low-confidence (<0.7): {int((df_imputed['data_confidence'] < 0.7).sum())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d9d3bb99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "column",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "original_fraction",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "imputed_fraction",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "univariate_outlier_fraction",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "834b369f-b53d-4f9f-846b-f150f1b062ea",
       "rows": [
        [
         "12",
         "Controversy Score",
         "0.8011928429423459",
         "0.1988071570576541",
         "0.43339960238568587"
        ],
        [
         "9",
         "Governance Risk Score",
         "0.8548707753479126",
         "0.14512922465208747",
         "0.03777335984095427"
        ],
        [
         "10",
         "Social Risk Score",
         "0.8548707753479126",
         "0.14512922465208747",
         "0.03578528827037773"
        ],
        [
         "8",
         "Environment Risk Score",
         "0.8548707753479126",
         "0.14512922465208747",
         "0.017892644135188866"
        ],
        [
         "7",
         "Total ESG Risk score",
         "0.8548707753479126",
         "0.14512922465208747",
         "0.013916500994035786"
        ],
        [
         "15",
         "ESG_Risk_Percentile_Numeric",
         "0.8548707753479126",
         "0.14512922465208747",
         "0.0"
        ],
        [
         "11",
         "Controversy Level",
         "0.8548707753479126",
         "0.14512922465208747",
         null
        ],
        [
         "13",
         "ESG Risk Percentile",
         "0.8548707753479126",
         "0.14512922465208747",
         null
        ],
        [
         "14",
         "ESG Risk Level",
         "0.8548707753479126",
         "0.14512922465208747",
         null
        ],
        [
         "5",
         "Full Time Employees",
         "0.9900596421471173",
         "0.009940357852882704",
         "0.10337972166998012"
        ],
        [
         "2",
         "Address",
         "0.9980119284294234",
         "0.0019880715705765406",
         null
        ],
        [
         "3",
         "Sector",
         "0.9980119284294234",
         "0.0019880715705765406",
         null
        ],
        [
         "4",
         "Industry",
         "0.9980119284294234",
         "0.0019880715705765406",
         null
        ],
        [
         "6",
         "Description",
         "0.9980119284294234",
         "0.0019880715705765406",
         null
        ],
        [
         "0",
         "Symbol",
         "1.0",
         "0.0",
         null
        ],
        [
         "1",
         "Name",
         "1.0",
         "0.0",
         null
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 16
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>original_fraction</th>\n",
       "      <th>imputed_fraction</th>\n",
       "      <th>univariate_outlier_fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Controversy Score</td>\n",
       "      <td>0.801193</td>\n",
       "      <td>0.198807</td>\n",
       "      <td>0.433400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Governance Risk Score</td>\n",
       "      <td>0.854871</td>\n",
       "      <td>0.145129</td>\n",
       "      <td>0.037773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Social Risk Score</td>\n",
       "      <td>0.854871</td>\n",
       "      <td>0.145129</td>\n",
       "      <td>0.035785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Environment Risk Score</td>\n",
       "      <td>0.854871</td>\n",
       "      <td>0.145129</td>\n",
       "      <td>0.017893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Total ESG Risk score</td>\n",
       "      <td>0.854871</td>\n",
       "      <td>0.145129</td>\n",
       "      <td>0.013917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ESG_Risk_Percentile_Numeric</td>\n",
       "      <td>0.854871</td>\n",
       "      <td>0.145129</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Controversy Level</td>\n",
       "      <td>0.854871</td>\n",
       "      <td>0.145129</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ESG Risk Percentile</td>\n",
       "      <td>0.854871</td>\n",
       "      <td>0.145129</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ESG Risk Level</td>\n",
       "      <td>0.854871</td>\n",
       "      <td>0.145129</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Full Time Employees</td>\n",
       "      <td>0.990060</td>\n",
       "      <td>0.009940</td>\n",
       "      <td>0.103380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Address</td>\n",
       "      <td>0.998012</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sector</td>\n",
       "      <td>0.998012</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Industry</td>\n",
       "      <td>0.998012</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Description</td>\n",
       "      <td>0.998012</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Symbol</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Name</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         column  original_fraction  imputed_fraction  \\\n",
       "12            Controversy Score           0.801193          0.198807   \n",
       "9         Governance Risk Score           0.854871          0.145129   \n",
       "10            Social Risk Score           0.854871          0.145129   \n",
       "8        Environment Risk Score           0.854871          0.145129   \n",
       "7          Total ESG Risk score           0.854871          0.145129   \n",
       "15  ESG_Risk_Percentile_Numeric           0.854871          0.145129   \n",
       "11            Controversy Level           0.854871          0.145129   \n",
       "13          ESG Risk Percentile           0.854871          0.145129   \n",
       "14               ESG Risk Level           0.854871          0.145129   \n",
       "5           Full Time Employees           0.990060          0.009940   \n",
       "2                       Address           0.998012          0.001988   \n",
       "3                        Sector           0.998012          0.001988   \n",
       "4                      Industry           0.998012          0.001988   \n",
       "6                   Description           0.998012          0.001988   \n",
       "0                        Symbol           1.000000          0.000000   \n",
       "1                          Name           1.000000          0.000000   \n",
       "\n",
       "    univariate_outlier_fraction  \n",
       "12                     0.433400  \n",
       "9                      0.037773  \n",
       "10                     0.035785  \n",
       "8                      0.017893  \n",
       "7                      0.013917  \n",
       "15                     0.000000  \n",
       "11                          NaN  \n",
       "13                          NaN  \n",
       "14                          NaN  \n",
       "5                      0.103380  \n",
       "2                           NaN  \n",
       "3                           NaN  \n",
       "4                           NaN  \n",
       "6                           NaN  \n",
       "0                           NaN  \n",
       "1                           NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quality_cols = [c for c in df.columns if c in df_imputed.columns]\n",
    "col_quality = []\n",
    "for c in quality_cols:\n",
    "    original_fraction = 1.0 - float(missingness_original[c].mean()) if c in missingness_original.columns else np.nan\n",
    "    imputed_fraction_col = float(missingness_original[c].mean()) if c in missingness_original.columns else np.nan\n",
    "    outlier_fraction_col = np.nan\n",
    "    if c in bounds:\n",
    "        lb, ub = bounds[c]\n",
    "        v = pd.to_numeric(df_imputed[c], errors='coerce')\n",
    "        outlier_fraction_col = float(((v < lb) | (v > ub)).mean())\n",
    "    col_quality.append({'column': c, 'original_fraction': original_fraction, 'imputed_fraction': imputed_fraction_col, 'univariate_outlier_fraction': outlier_fraction_col})\n",
    "col_quality_df = pd.DataFrame(col_quality).sort_values(['imputed_fraction', 'univariate_outlier_fraction'], ascending=False)\n",
    "display(col_quality_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "23869d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß STEP 8: FEATURE ENGINEERING\n",
      "===================================\n",
      "‚úÖ Created ESG_Component_Balance (std of E, S, G scores)\n",
      "‚úÖ Created ESG_Max_Component and ESG_Min_Component\n",
      "‚úÖ Created Employee_Size_Category (Small/Medium/Large/Enterprise)\n",
      "‚úÖ Created Log_Employees (log-transformed employee count)\n",
      "‚úÖ Created ESG_Risk_Above_Average (threshold: 21.5)\n",
      "‚úÖ Created ESG_Risk_Category (Low/Medium/High/Severe)\n",
      "‚úÖ Created Sector_Risk_Average and ESG_vs_Sector_Average\n",
      "‚úÖ Created High_Risk_Percentile (>75th percentile flag)\n",
      "\n",
      "üìä Feature Engineering Summary:\n",
      "   Original features: 27\n",
      "   New features: 10\n",
      "   Total features: 37\n",
      "\n",
      "üÜï New features created:\n",
      "   1. ESG_Component_Balance\n",
      "   2. ESG_Max_Component\n",
      "   3. ESG_Min_Component\n",
      "   4. Employee_Size_Category\n",
      "   5. Log_Employees\n",
      "   6. ESG_Risk_Above_Average\n",
      "   7. ESG_Risk_Category\n",
      "   8. Sector_Risk_Average\n",
      "   9. ESG_vs_Sector_Average\n",
      "   10. High_Risk_Percentile\n"
     ]
    }
   ],
   "source": [
    "print(\"üîß STEP 8: FEATURE ENGINEERING\")\n",
    "print(\"=\" * 35)\n",
    "df_featured = df_imputed.copy()\n",
    "if len([col for col in esg_columns if col in df_featured.columns]) >= 3:\n",
    "    if all(col in df_featured.columns for col in ['Environment Risk Score', 'Social Risk Score', 'Governance Risk Score']):\n",
    "        df_featured['ESG_Component_Balance'] = df_featured[['Environment Risk Score', 'Social Risk Score', 'Governance Risk Score']].std(axis=1)\n",
    "        print(\"‚úÖ Created ESG_Component_Balance (std of E, S, G scores)\")\n",
    "        \n",
    "        df_featured['ESG_Max_Component'] = df_featured[['Environment Risk Score', 'Social Risk Score', 'Governance Risk Score']].max(axis=1)\n",
    "        df_featured['ESG_Min_Component'] = df_featured[['Environment Risk Score', 'Social Risk Score', 'Governance Risk Score']].min(axis=1)\n",
    "        print(\"‚úÖ Created ESG_Max_Component and ESG_Min_Component\")\n",
    "if 'Full Time Employees' in df_featured.columns:\n",
    "    df_featured['Employee_Size_Category'] = pd.cut(\n",
    "        df_featured['Full Time Employees'], \n",
    "        bins=[0, 1000, 10000, 50000, float('inf')], \n",
    "        labels=['Small', 'Medium', 'Large', 'Enterprise'],\n",
    "        include_lowest=True\n",
    "    )\n",
    "    print(\"‚úÖ Created Employee_Size_Category (Small/Medium/Large/Enterprise)\")\n",
    "    \n",
    "    df_featured['Log_Employees'] = np.log1p(df_featured['Full Time Employees'])\n",
    "    print(\"‚úÖ Created Log_Employees (log-transformed employee count)\")\n",
    "if 'Total ESG Risk score' in df_featured.columns:\n",
    "    esg_risk_mean = df_featured['Total ESG Risk score'].mean()\n",
    "    df_featured['ESG_Risk_Above_Average'] = (df_featured['Total ESG Risk score'] > esg_risk_mean).astype(int)\n",
    "    print(f\"‚úÖ Created ESG_Risk_Above_Average (threshold: {esg_risk_mean:.1f})\")\n",
    "    \n",
    "    df_featured['ESG_Risk_Category'] = pd.cut(\n",
    "        df_featured['Total ESG Risk score'],\n",
    "        bins=[0, 15, 25, 35, float('inf')],\n",
    "        labels=['Low', 'Medium', 'High', 'Severe'],\n",
    "        include_lowest=True\n",
    "    )\n",
    "    print(\"‚úÖ Created ESG_Risk_Category (Low/Medium/High/Severe)\")\n",
    "if 'Sector' in df_featured.columns:\n",
    "    sector_risk_avg = df_featured.groupby('Sector')['Total ESG Risk score'].mean()\n",
    "    df_featured['Sector_Risk_Average'] = df_featured['Sector'].map(sector_risk_avg)\n",
    "    df_featured['ESG_vs_Sector_Average'] = df_featured['Total ESG Risk score'] - df_featured['Sector_Risk_Average']\n",
    "    print(\"‚úÖ Created Sector_Risk_Average and ESG_vs_Sector_Average\")\n",
    "if 'ESG Risk Percentile' in df_featured.columns and 'ESG_Risk_Percentile_Numeric' in df_featured.columns:\n",
    "    df_featured['High_Risk_Percentile'] = (df_featured['ESG_Risk_Percentile_Numeric'] > 75).astype(int)\n",
    "    print(\"‚úÖ Created High_Risk_Percentile (>75th percentile flag)\")\n",
    "new_features = [col for col in df_featured.columns if col not in df_imputed.columns]\n",
    "print(f\"\\nüìä Feature Engineering Summary:\")\n",
    "print(f\"   Original features: {len(df_imputed.columns)}\")\n",
    "print(f\"   New features: {len(new_features)}\")\n",
    "print(f\"   Total features: {len(df_featured.columns)}\")\n",
    "if new_features:\n",
    "    print(f\"\\nüÜï New features created:\")\n",
    "    for i, feature in enumerate(new_features, 1):\n",
    "        print(f\"   {i}. {feature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "42ae99b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß STEP 9: ENCODING CATEGORICAL VARIABLES\n",
      "=============================================\n",
      "üìä Categorical columns to encode: 7\n",
      "\n",
      "üî§ Processing Sector:\n",
      "   Unique values: 11\n",
      "   ‚úÖ Label encoded as Sector_Encoded\n",
      "   üìù Keeping original Sector for reference\n",
      "\n",
      "üî§ Processing Industry:\n",
      "   Unique values: 116\n",
      "   ‚úÖ Label encoded as Industry_Encoded\n",
      "   üìù Keeping original Industry for reference\n",
      "\n",
      "üî§ Processing Controversy Level:\n",
      "   Unique values: 6\n",
      "   ‚úÖ One-hot encoded into 7 columns\n",
      "   üìù Keeping original Controversy Level for reference\n",
      "\n",
      "üî§ Processing ESG Risk Percentile:\n",
      "   Unique values: 89\n",
      "   ‚úÖ Label encoded as ESG Risk Percentile_Encoded\n",
      "   üìù Keeping original ESG Risk Percentile for reference\n",
      "\n",
      "üî§ Processing ESG Risk Level:\n",
      "   Unique values: 5\n",
      "   ‚úÖ One-hot encoded into 6 columns\n",
      "   üìù Keeping original ESG Risk Level for reference\n",
      "\n",
      "üî§ Processing Employee_Size_Category:\n",
      "   Unique values: 4\n",
      "   ‚úÖ One-hot encoded into 5 columns\n",
      "   üìù Keeping original Employee_Size_Category for reference\n",
      "\n",
      "üî§ Processing ESG_Risk_Category:\n",
      "   Unique values: 4\n",
      "   ‚úÖ One-hot encoded into 5 columns\n",
      "   üìù Keeping original ESG_Risk_Category for reference\n",
      "\n",
      "üìä Encoding Summary:\n",
      "   Columns after encoding: 63\n",
      "   New encoded columns: 26\n"
     ]
    }
   ],
   "source": [
    "print(\"üîß STEP 9: ENCODING CATEGORICAL VARIABLES\")\n",
    "print(\"=\" * 45)\n",
    "df_encoded = df_featured.copy()\n",
    "categorical_cols = df_encoded.select_dtypes(include=['object', 'category']).columns\n",
    "categorical_cols = [col for col in categorical_cols if col not in ['Symbol', 'Name', 'Address', 'Description']]\n",
    "print(f\"üìä Categorical columns to encode: {len(categorical_cols)}\")\n",
    "if len(categorical_cols) > 0:\n",
    "    for col in categorical_cols:\n",
    "        print(f\"\\nüî§ Processing {col}:\")\n",
    "        unique_count = df_encoded[col].nunique()\n",
    "        print(f\"   Unique values: {unique_count}\")\n",
    "        \n",
    "        if unique_count <= 10:\n",
    "            dummies = pd.get_dummies(df_encoded[col], prefix=f'{col}', dummy_na=True)\n",
    "            df_encoded = pd.concat([df_encoded, dummies], axis=1)\n",
    "            print(f\"   ‚úÖ One-hot encoded into {len(dummies.columns)} columns\")\n",
    "        else:\n",
    "            le = LabelEncoder()\n",
    "            df_encoded[f'{col}_Encoded'] = le.fit_transform(df_encoded[col].fillna('Unknown'))\n",
    "            print(f\"   ‚úÖ Label encoded as {col}_Encoded\")\n",
    "        \n",
    "        print(f\"   üìù Keeping original {col} for reference\")\n",
    "print(f\"\\nüìä Encoding Summary:\")\n",
    "print(f\"   Columns after encoding: {len(df_encoded.columns)}\")\n",
    "new_encoded_cols = [col for col in df_encoded.columns if col not in df_featured.columns]\n",
    "print(f\"   New encoded columns: {len(new_encoded_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "95c0ad12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation-pruned candidates to drop: 2\n",
      "['ESG_Risk_Percentile_Numeric', 'univariate_outlier_fraction']\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "feature",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "vif",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "c7b9be6b-687c-4890-9bb2-cf9b02e974dc",
       "rows": [
        [
         "0",
         "univariate_outlier_fraction",
         "1000000000000.0"
        ],
        [
         "1",
         "Sector_Risk_Average",
         "1000000000000.0"
        ],
        [
         "2",
         "ESG_Risk_Category_Medium",
         "1000000000000.0"
        ],
        [
         "3",
         "Employee_Size_Category_Enterprise",
         "1000000000000.0"
        ],
        [
         "4",
         "ESG_Risk_Category_High",
         "1000000000000.0"
        ],
        [
         "5",
         "Employee_Size_Category_Medium",
         "1000000000000.0"
        ],
        [
         "6",
         "Employee_Size_Category_Large",
         "1000000000000.0"
        ],
        [
         "7",
         "ESG_Risk_Category_Low",
         "1000000000000.0"
        ],
        [
         "8",
         "ESG_vs_Sector_Average",
         "1000000000000.0"
        ],
        [
         "9",
         "Total ESG Risk score",
         "1000000000000.0"
        ],
        [
         "10",
         "ESG_Risk_Category_Severe",
         "1000000000000.0"
        ],
        [
         "11",
         "Employee_Size_Category_Small",
         "1000000000000.0"
        ],
        [
         "12",
         "univariate_outlier_count",
         "1000000000000.0"
        ],
        [
         "13",
         "Environment Risk Score",
         "7962.651155204883"
        ],
        [
         "14",
         "Social Risk Score",
         "3969.7507284027865"
        ],
        [
         "15",
         "Governance Risk Score",
         "1656.3929873041911"
        ],
        [
         "16",
         "Controversy Level_Low Controversy Level",
         "626.173019057813"
        ],
        [
         "17",
         "Controversy Level_Moderate Controversy Level",
         "597.3261017726297"
        ],
        [
         "18",
         "ESG_Risk_Percentile_Numeric",
         "392.7953997956692"
        ],
        [
         "19",
         "ESG_Max_Component",
         "173.65235372378334"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>vif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>univariate_outlier_fraction</td>\n",
       "      <td>1.000000e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sector_Risk_Average</td>\n",
       "      <td>1.000000e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ESG_Risk_Category_Medium</td>\n",
       "      <td>1.000000e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Employee_Size_Category_Enterprise</td>\n",
       "      <td>1.000000e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESG_Risk_Category_High</td>\n",
       "      <td>1.000000e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Employee_Size_Category_Medium</td>\n",
       "      <td>1.000000e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Employee_Size_Category_Large</td>\n",
       "      <td>1.000000e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ESG_Risk_Category_Low</td>\n",
       "      <td>1.000000e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ESG_vs_Sector_Average</td>\n",
       "      <td>1.000000e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Total ESG Risk score</td>\n",
       "      <td>1.000000e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ESG_Risk_Category_Severe</td>\n",
       "      <td>1.000000e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Employee_Size_Category_Small</td>\n",
       "      <td>1.000000e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>univariate_outlier_count</td>\n",
       "      <td>1.000000e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Environment Risk Score</td>\n",
       "      <td>7.962651e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Social Risk Score</td>\n",
       "      <td>3.969751e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Governance Risk Score</td>\n",
       "      <td>1.656393e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Controversy Level_Low Controversy Level</td>\n",
       "      <td>6.261730e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Controversy Level_Moderate Controversy Level</td>\n",
       "      <td>5.973261e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ESG_Risk_Percentile_Numeric</td>\n",
       "      <td>3.927954e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ESG_Max_Component</td>\n",
       "      <td>1.736524e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         feature           vif\n",
       "0                    univariate_outlier_fraction  1.000000e+12\n",
       "1                            Sector_Risk_Average  1.000000e+12\n",
       "2                       ESG_Risk_Category_Medium  1.000000e+12\n",
       "3              Employee_Size_Category_Enterprise  1.000000e+12\n",
       "4                         ESG_Risk_Category_High  1.000000e+12\n",
       "5                  Employee_Size_Category_Medium  1.000000e+12\n",
       "6                   Employee_Size_Category_Large  1.000000e+12\n",
       "7                          ESG_Risk_Category_Low  1.000000e+12\n",
       "8                          ESG_vs_Sector_Average  1.000000e+12\n",
       "9                           Total ESG Risk score  1.000000e+12\n",
       "10                      ESG_Risk_Category_Severe  1.000000e+12\n",
       "11                  Employee_Size_Category_Small  1.000000e+12\n",
       "12                      univariate_outlier_count  1.000000e+12\n",
       "13                        Environment Risk Score  7.962651e+03\n",
       "14                             Social Risk Score  3.969751e+03\n",
       "15                         Governance Risk Score  1.656393e+03\n",
       "16       Controversy Level_Low Controversy Level  6.261730e+02\n",
       "17  Controversy Level_Moderate Controversy Level  5.973261e+02\n",
       "18                   ESG_Risk_Percentile_Numeric  3.927954e+02\n",
       "19                             ESG_Max_Component  1.736524e+02"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: 63 -> 61\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = df_encoded.select_dtypes(include=[np.number]).columns.tolist()\n",
    "excluded = [c for c in numeric_cols if str(c).endswith('_was_missing') or str(c).endswith('_flag') or str(c).startswith('prov_')]\n",
    "candidates = [c for c in numeric_cols if c not in excluded]\n",
    "drop_corr = correlation_prune(df_encoded, candidates, threshold=0.95)\n",
    "vif_table = compute_vif(df_encoded, candidates, max_features=40)\n",
    "print(f\"Correlation-pruned candidates to drop: {len(drop_corr)}\")\n",
    "if len(drop_corr) > 0:\n",
    "    print(drop_corr[:30])\n",
    "display(vif_table.head(20))\n",
    "df_encoded_reduced = df_encoded.drop(columns=drop_corr, errors='ignore')\n",
    "print(f\"Columns: {df_encoded.shape[1]} -> {df_encoded_reduced.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ed9abf0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß STEP 10: FEATURE SCALING AND NORMALIZATION\n",
      "==================================================\n",
      "üìä Columns to scale: 29\n",
      "‚úÖ Sector-wise standardization applied\n"
     ]
    }
   ],
   "source": [
    "print(\"üîß STEP 10: FEATURE SCALING AND NORMALIZATION\")\n",
    "print(\"=\" * 50)\n",
    "df_final = (df_encoded_reduced.copy() if 'df_encoded_reduced' in globals() else df_encoded.copy())\n",
    "numeric_cols_to_scale = df_final.select_dtypes(include=[np.number]).columns\n",
    "exclude_from_scaling = ['Symbol', 'Name', 'Address', 'Description'] +                       [col for col in df_final.columns if '_was_missing' in col or                        col.endswith('_Encoded') or                        col.endswith('_flag') or                        col.startswith('prov_') or                        col.startswith(tuple(['Sector_', 'Industry_', 'Controversy Level_', 'ESG Risk Level_']))]\n",
    "scale_cols = [col for col in numeric_cols_to_scale if col not in exclude_from_scaling]\n",
    "print(f\"üìä Columns to scale: {len(scale_cols)}\")\n",
    "if len(scale_cols) > 0:\n",
    "    if 'Sector' in df_final.columns:\n",
    "        df_final_scaled = df_final.copy()\n",
    "        scaler_global = StandardScaler()\n",
    "        sector_values = df_final['Sector'].astype(str)\n",
    "        for sector in sector_values.unique():\n",
    "            idx = sector_values == sector\n",
    "            if idx.sum() < 5:\n",
    "                continue\n",
    "            scaler = StandardScaler()\n",
    "            df_final_scaled.loc[idx, scale_cols] = scaler.fit_transform(df_final.loc[idx, scale_cols])\n",
    "        missing_scaled = df_final_scaled[scale_cols].isna().any(axis=1)\n",
    "        if missing_scaled.any():\n",
    "            df_final_scaled.loc[missing_scaled, scale_cols] = scaler_global.fit_transform(df_final.loc[missing_scaled, scale_cols])\n",
    "        df_final = df_final_scaled\n",
    "        print(\"‚úÖ Sector-wise standardization applied\")\n",
    "    else:\n",
    "        scaler = StandardScaler()\n",
    "        df_final[scale_cols] = scaler.fit_transform(df_final[scale_cols])\n",
    "        print(f\"‚úÖ Standardized {len(scale_cols)} numeric columns\")\n",
    "else:\n",
    "    print(\"‚ùå No columns found for scaling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "39ba47fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "feature",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ks_stat",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ks_pvalue",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "psi",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "61234fc6-4e4b-4fef-be9f-9a82afd5ff7d",
       "rows": [
        [
         "0",
         "ESG_Component_Balance",
         "0.061397675817738515",
         "0.6989104202345366",
         "0.08543064049627244"
        ],
        [
         "1",
         "ESG Risk Percentile_Encoded",
         "0.08289794496691048",
         "0.32925847907773154",
         "0.07951335952457313"
        ],
        [
         "2",
         "Log_Employees",
         "0.07238529495582788",
         "0.49513762829203567",
         "0.0784373340500855"
        ],
        [
         "3",
         "ESG_Max_Component",
         "0.051201671891327065",
         "0.8732702889251804",
         "0.07695194095513587"
        ],
        [
         "4",
         "Employee_Size_Category_Large",
         "0.06698647921218454",
         "0.5933280285859986",
         "0.058663615472123454"
        ],
        [
         "5",
         "ESG_Risk_Category_Medium",
         "0.08178968367056141",
         "0.34467143676443973",
         "0.05804855286368554"
        ],
        [
         "6",
         "mv_isolation_forest_score",
         "0.06598904404547037",
         "0.612142774493674",
         "0.057651973177675606"
        ],
        [
         "7",
         "ESG_Min_Component",
         "0.07149868591874861",
         "0.5107062305476386",
         "0.056889281695671395"
        ],
        [
         "8",
         "Total ESG Risk score",
         "0.08207466514676547",
         "0.34073883473607586",
         "0.04973721082911757"
        ],
        [
         "9",
         "ESG_vs_Sector_Average",
         "0.08207466514676547",
         "0.34073883473607586",
         "0.04973721082911757"
        ],
        [
         "10",
         "data_confidence",
         "0.06464329818561794",
         "0.6375654843461951",
         "0.04898404420518722"
        ],
        [
         "11",
         "Full Time Employees",
         "0.07328773629714068",
         "0.47939949422595296",
         "0.047342174187437004"
        ],
        [
         "12",
         "Employee_Size_Category_Enterprise",
         "0.06735062220955639",
         "0.5866187334822974",
         "0.04305895883604268"
        ],
        [
         "13",
         "ESG_Risk_Category_High",
         "0.05240492701307748",
         "0.8553243965983343",
         "0.040889023628686884"
        ],
        [
         "14",
         "Social Risk Score",
         "0.06560906874386498",
         "0.6193539631803434",
         "0.03824227339208979"
        ],
        [
         "15",
         "Environment Risk Score",
         "0.0794465026439948",
         "0.3792434420282709",
         "0.037894493108279775"
        ],
        [
         "16",
         "Controversy Score",
         "0.03821918241980938",
         "0.9881914358361247",
         "0.03714277829693515"
        ],
        [
         "17",
         "mv_lof_score",
         "0.05200911940723853",
         "0.8614826581436479",
         "0.03632183360810384"
        ],
        [
         "18",
         "ESG_Risk_Above_Average",
         "0.05810455653715842",
         "0.7595964105961319",
         "0.0345723936203841"
        ],
        [
         "19",
         "Governance Risk Score",
         "0.04790855261074697",
         "0.9165049456645468",
         "0.03326554758646795"
        ],
        [
         "20",
         "Employee_Size_Category_Medium",
         "0.03486273392229505",
         "0.9960638249536127",
         "0.031040030103004768"
        ],
        [
         "21",
         "ESG_Risk_Category_Low",
         "0.04258889838827143",
         "0.9661970441370229",
         "0.02965293409057705"
        ],
        [
         "22",
         "High_Risk_Percentile",
         "0.0502042367246129",
         "0.8874231033831181",
         "0.02941561590903133"
        ],
        [
         "23",
         "mv_mahalanobis",
         "0.08817010227668536",
         "0.26177621350346914",
         "0.029269646110434346"
        ],
        [
         "24",
         "Sector_Encoded",
         "0.02357430100376809",
         "0.9999981803022917",
         "0.028158693116115123"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 25
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>ks_stat</th>\n",
       "      <th>ks_pvalue</th>\n",
       "      <th>psi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ESG_Component_Balance</td>\n",
       "      <td>0.061398</td>\n",
       "      <td>0.698910</td>\n",
       "      <td>0.085431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESG Risk Percentile_Encoded</td>\n",
       "      <td>0.082898</td>\n",
       "      <td>0.329258</td>\n",
       "      <td>0.079513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Log_Employees</td>\n",
       "      <td>0.072385</td>\n",
       "      <td>0.495138</td>\n",
       "      <td>0.078437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ESG_Max_Component</td>\n",
       "      <td>0.051202</td>\n",
       "      <td>0.873270</td>\n",
       "      <td>0.076952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Employee_Size_Category_Large</td>\n",
       "      <td>0.066986</td>\n",
       "      <td>0.593328</td>\n",
       "      <td>0.058664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ESG_Risk_Category_Medium</td>\n",
       "      <td>0.081790</td>\n",
       "      <td>0.344671</td>\n",
       "      <td>0.058049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mv_isolation_forest_score</td>\n",
       "      <td>0.065989</td>\n",
       "      <td>0.612143</td>\n",
       "      <td>0.057652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ESG_Min_Component</td>\n",
       "      <td>0.071499</td>\n",
       "      <td>0.510706</td>\n",
       "      <td>0.056889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Total ESG Risk score</td>\n",
       "      <td>0.082075</td>\n",
       "      <td>0.340739</td>\n",
       "      <td>0.049737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ESG_vs_Sector_Average</td>\n",
       "      <td>0.082075</td>\n",
       "      <td>0.340739</td>\n",
       "      <td>0.049737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>data_confidence</td>\n",
       "      <td>0.064643</td>\n",
       "      <td>0.637565</td>\n",
       "      <td>0.048984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Full Time Employees</td>\n",
       "      <td>0.073288</td>\n",
       "      <td>0.479399</td>\n",
       "      <td>0.047342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Employee_Size_Category_Enterprise</td>\n",
       "      <td>0.067351</td>\n",
       "      <td>0.586619</td>\n",
       "      <td>0.043059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ESG_Risk_Category_High</td>\n",
       "      <td>0.052405</td>\n",
       "      <td>0.855324</td>\n",
       "      <td>0.040889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Social Risk Score</td>\n",
       "      <td>0.065609</td>\n",
       "      <td>0.619354</td>\n",
       "      <td>0.038242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Environment Risk Score</td>\n",
       "      <td>0.079447</td>\n",
       "      <td>0.379243</td>\n",
       "      <td>0.037894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Controversy Score</td>\n",
       "      <td>0.038219</td>\n",
       "      <td>0.988191</td>\n",
       "      <td>0.037143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mv_lof_score</td>\n",
       "      <td>0.052009</td>\n",
       "      <td>0.861483</td>\n",
       "      <td>0.036322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ESG_Risk_Above_Average</td>\n",
       "      <td>0.058105</td>\n",
       "      <td>0.759596</td>\n",
       "      <td>0.034572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Governance Risk Score</td>\n",
       "      <td>0.047909</td>\n",
       "      <td>0.916505</td>\n",
       "      <td>0.033266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Employee_Size_Category_Medium</td>\n",
       "      <td>0.034863</td>\n",
       "      <td>0.996064</td>\n",
       "      <td>0.031040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ESG_Risk_Category_Low</td>\n",
       "      <td>0.042589</td>\n",
       "      <td>0.966197</td>\n",
       "      <td>0.029653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>High_Risk_Percentile</td>\n",
       "      <td>0.050204</td>\n",
       "      <td>0.887423</td>\n",
       "      <td>0.029416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>mv_mahalanobis</td>\n",
       "      <td>0.088170</td>\n",
       "      <td>0.261776</td>\n",
       "      <td>0.029270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Sector_Encoded</td>\n",
       "      <td>0.023574</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.028159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              feature   ks_stat  ks_pvalue       psi\n",
       "0               ESG_Component_Balance  0.061398   0.698910  0.085431\n",
       "1         ESG Risk Percentile_Encoded  0.082898   0.329258  0.079513\n",
       "2                       Log_Employees  0.072385   0.495138  0.078437\n",
       "3                   ESG_Max_Component  0.051202   0.873270  0.076952\n",
       "4        Employee_Size_Category_Large  0.066986   0.593328  0.058664\n",
       "5            ESG_Risk_Category_Medium  0.081790   0.344671  0.058049\n",
       "6           mv_isolation_forest_score  0.065989   0.612143  0.057652\n",
       "7                   ESG_Min_Component  0.071499   0.510706  0.056889\n",
       "8                Total ESG Risk score  0.082075   0.340739  0.049737\n",
       "9               ESG_vs_Sector_Average  0.082075   0.340739  0.049737\n",
       "10                    data_confidence  0.064643   0.637565  0.048984\n",
       "11                Full Time Employees  0.073288   0.479399  0.047342\n",
       "12  Employee_Size_Category_Enterprise  0.067351   0.586619  0.043059\n",
       "13             ESG_Risk_Category_High  0.052405   0.855324  0.040889\n",
       "14                  Social Risk Score  0.065609   0.619354  0.038242\n",
       "15             Environment Risk Score  0.079447   0.379243  0.037894\n",
       "16                  Controversy Score  0.038219   0.988191  0.037143\n",
       "17                       mv_lof_score  0.052009   0.861483  0.036322\n",
       "18             ESG_Risk_Above_Average  0.058105   0.759596  0.034572\n",
       "19              Governance Risk Score  0.047909   0.916505  0.033266\n",
       "20      Employee_Size_Category_Medium  0.034863   0.996064  0.031040\n",
       "21              ESG_Risk_Category_Low  0.042589   0.966197  0.029653\n",
       "22               High_Risk_Percentile  0.050204   0.887423  0.029416\n",
       "23                     mv_mahalanobis  0.088170   0.261776  0.029270\n",
       "24                     Sector_Encoded  0.023574   0.999998  0.028159"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with PSI>0.2: 0\n"
     ]
    }
   ],
   "source": [
    "numeric_cols_drift = [c for c in df_final.select_dtypes(include=[np.number]).columns if c not in ['univariate_outlier_count', 'univariate_outlier_fraction']]\n",
    "rng = np.random.RandomState(42)\n",
    "mask = rng.rand(len(df_final)) < 0.5\n",
    "df_a = df_final.loc[mask]\n",
    "df_b = df_final.loc[~mask]\n",
    "drift_rows = []\n",
    "for c in numeric_cols_drift:\n",
    "    a = pd.to_numeric(df_a[c], errors='coerce')\n",
    "    b = pd.to_numeric(df_b[c], errors='coerce')\n",
    "    if a.notna().sum() < 10 or b.notna().sum() < 10:\n",
    "        continue\n",
    "    ks = ks_2samp(a.dropna().values, b.dropna().values)\n",
    "    psi = psi_numeric(a, b, bins=10)\n",
    "    drift_rows.append({'feature': c, 'ks_stat': float(ks.statistic), 'ks_pvalue': float(ks.pvalue), 'psi': psi})\n",
    "drift_df = pd.DataFrame(drift_rows)\n",
    "if len(drift_df) > 0:\n",
    "    drift_df = drift_df.sort_values(['psi', 'ks_stat'], ascending=False).reset_index(drop=True)\n",
    "    display(drift_df.head(25))\n",
    "    print(f\"Features with PSI>0.2: {int((drift_df['psi'] > 0.2).sum())}\")\n",
    "else:\n",
    "    print(\"No drift metrics computed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "362a9654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä FINAL DATA QUALITY ASSESSMENT\n",
      "=============================================\n",
      "üéØ Processing Summary:\n",
      "   Original shape: (503, 15)\n",
      "   Final shape: (503, 61)\n",
      "   Rows added/removed: +0\n",
      "   Columns added: +46\n",
      "\n",
      "üìà Data Quality Metrics:\n",
      "   Original completeness: 91.8%\n",
      "   Final completeness: 100.0%\n",
      "   Improvement: +8.2%\n",
      "\n",
      "üî¢ Column Types:\n",
      "   Numeric columns: 50\n",
      "   Categorical columns: 11\n",
      "   Total columns: 61\n",
      "\n",
      "‚úÖ No missing values remaining!\n",
      "\n",
      "üéØ Ready for Machine Learning:\n",
      "   ML-ready numeric features: 30\n",
      "   Memory usage: 1.14 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä FINAL DATA QUALITY ASSESSMENT\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"üéØ Processing Summary:\")\n",
    "print(f\"   Original shape: {df_raw.shape}\")\n",
    "print(f\"   Final shape: {df_final.shape}\")\n",
    "print(f\"   Rows added/removed: {df_final.shape[0] - df_raw.shape[0]:+d}\")\n",
    "print(f\"   Columns added: {df_final.shape[1] - df_raw.shape[1]:+d}\")\n",
    "print(f\"\\nüìà Data Quality Metrics:\")\n",
    "original_completeness = ((df_raw.shape[0] * df_raw.shape[1] - df_raw.isnull().sum().sum()) / (df_raw.shape[0] * df_raw.shape[1]) * 100)\n",
    "final_completeness = ((df_final.shape[0] * df_final.shape[1] - df_final.isnull().sum().sum()) / (df_final.shape[0] * df_final.shape[1]) * 100)\n",
    "print(f\"   Original completeness: {original_completeness:.1f}%\")\n",
    "print(f\"   Final completeness: {final_completeness:.1f}%\")\n",
    "print(f\"   Improvement: {final_completeness - original_completeness:+.1f}%\")\n",
    "print(f\"\\nüî¢ Column Types:\")\n",
    "numeric_count = len(df_final.select_dtypes(include=[np.number]).columns)\n",
    "categorical_count = len(df_final.select_dtypes(include=['object', 'category']).columns)\n",
    "print(f\"   Numeric columns: {numeric_count}\")\n",
    "print(f\"   Categorical columns: {categorical_count}\")\n",
    "print(f\"   Total columns: {len(df_final.columns)}\")\n",
    "remaining_missing = df_final.isnull().sum().sum()\n",
    "if remaining_missing > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è  Remaining missing values: {remaining_missing}\")\n",
    "    missing_cols = df_final.columns[df_final.isnull().any()].tolist()\n",
    "    for col in missing_cols[:5]:\n",
    "        missing_count = df_final[col].isnull().sum()\n",
    "        print(f\"   {col}: {missing_count} missing\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ No missing values remaining!\")\n",
    "print(f\"\\nüéØ Ready for Machine Learning:\")\n",
    "ml_ready_cols = [col for col in df_final.columns \n",
    "                if col not in ['Symbol', 'Name', 'Address', 'Description'] \n",
    "                and df_final[col].dtype in [np.number, 'int64', 'float64']]\n",
    "print(f\"   ML-ready numeric features: {len(ml_ready_cols)}\")\n",
    "print(f\"   Memory usage: {df_final.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d059c1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ SAVING PROCESSED DATA\n",
      "==============================\n",
      "‚úÖ Processed data saved to: ../data/processed/processed.csv\n",
      "üìä File size: 1.04 MB\n",
      "‚úÖ Processing metadata saved to: ../data/processed/processing_metadata.txt\n",
      "\n",
      "üéâ DATA PREPROCESSING COMPLETED SUCCESSFULLY!\n",
      "üìà Dataset ready for machine learning and advanced analytics\n",
      "üìÅ Processed files location: ../data/processed/\n",
      "‚è±Ô∏è  Processing completed at: 2026-01-28 23:39:46\n"
     ]
    }
   ],
   "source": [
    "print(\"üíæ SAVING PROCESSED DATA\")\n",
    "print(\"=\" * 30)\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "processed_file_path = os.path.join(output_path, 'processed.csv')\n",
    "metadata_file_path = os.path.join(output_path, 'processing_metadata.txt')\n",
    "try:\n",
    "    df_final.to_csv(processed_file_path, index=False)\n",
    "    print(f\"‚úÖ Processed data saved to: {processed_file_path}\")\n",
    "    print(f\"üìä File size: {os.path.getsize(processed_file_path) / 1024**2:.2f} MB\")\n",
    "    \n",
    "    metadata = f\"\"\"ESG SUSTAINABILITY DATA PROCESSING METADATA\n",
    "Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "====================================================\n",
    "\n",
    "ORIGINAL DATA:\n",
    "- Shape: {df_raw.shape}\n",
    "- Completeness: {original_completeness:.1f}%\n",
    "- Missing values: {df_raw.isnull().sum().sum():,}\n",
    "\n",
    "PROCESSED DATA:\n",
    "- Shape: {df_final.shape}\n",
    "- Completeness: {final_completeness:.1f}%\n",
    "- Missing values: {df_final.isnull().sum().sum():,}\n",
    "- ML-ready features: {len(ml_ready_cols)}\n",
    "\n",
    "PROCESSING STEPS:\n",
    "1. ‚úÖ Basic cleaning (duplicates, symbols)\n",
    "2. ‚úÖ Employee data standardization\n",
    "3. ‚úÖ ESG scores preprocessing\n",
    "4. ‚úÖ Categorical data standardization\n",
    "5. ‚úÖ Missing value imputation\n",
    "6. ‚úÖ Outlier detection and treatment\n",
    "7. ‚úÖ Feature engineering\n",
    "8. ‚úÖ Categorical encoding\n",
    "9. ‚úÖ Feature scaling/normalization\n",
    "10. ‚úÖ Final quality assessment\n",
    "\n",
    "NEW FEATURES CREATED:\n",
    "{chr(10).join([f\"- {feature}\" for feature in new_features])}\n",
    "\n",
    "ENCODED COLUMNS:\n",
    "{chr(10).join([f\"- {col}\" for col in new_encoded_cols])}\n",
    "\n",
    "IMPUTATION STRATEGIES USED:\n",
    "{chr(10).join([f\"- {strategy}: {count} columns\" for strategy, count in strategy_counts.items()])}\n",
    "\n",
    "READY FOR:\n",
    "- Machine Learning model training\n",
    "- Statistical analysis\n",
    "- Predictive modeling\n",
    "- ESG risk assessment\n",
    "\"\"\"\n",
    "\n",
    "    with open(metadata_file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(metadata)\n",
    "    \n",
    "    print(f\"‚úÖ Processing metadata saved to: {metadata_file_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error saving files: {e}\")\n",
    "\n",
    "print(f\"\\nüéâ DATA PREPROCESSING COMPLETED SUCCESSFULLY!\")\n",
    "print(f\"üìà Dataset ready for machine learning and advanced analytics\")\n",
    "print(f\"üìÅ Processed files location: {output_path}\")\n",
    "print(f\"‚è±Ô∏è  Processing completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9c4e7a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç PROCESSED DATA SAMPLE PREVIEW\n",
      "========================================\n",
      "üìã Final Dataset Shape: (503, 61)\n",
      "\n",
      "üìä First 3 rows of key columns:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Symbol",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sector",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Total ESG Risk score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ESG_Risk_Category",
         "rawType": "category",
         "type": "unknown"
        },
        {
         "name": "Employee_Size_Category",
         "rawType": "category",
         "type": "unknown"
        }
       ],
       "ref": "d0a76065-7d06-497e-9f77-a9506e85713e",
       "rows": [
        [
         "0",
         "ENPH",
         "Enphase Energy, Inc.",
         "Technology",
         "0.7705260417063304",
         "Medium",
         "Medium"
        ],
        [
         "1",
         "EMN",
         "Eastman Chemical Company",
         "Basic Materials",
         "-0.13387209660470925",
         "High",
         "Large"
        ],
        [
         "2",
         "DPZ",
         "Domino's Pizza Inc.",
         "Consumer Cyclical",
         "1.7599068107115488",
         "High",
         "Medium"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Total ESG Risk score</th>\n",
       "      <th>ESG_Risk_Category</th>\n",
       "      <th>Employee_Size_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENPH</td>\n",
       "      <td>Enphase Energy, Inc.</td>\n",
       "      <td>Technology</td>\n",
       "      <td>0.770526</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EMN</td>\n",
       "      <td>Eastman Chemical Company</td>\n",
       "      <td>Basic Materials</td>\n",
       "      <td>-0.133872</td>\n",
       "      <td>High</td>\n",
       "      <td>Large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DPZ</td>\n",
       "      <td>Domino's Pizza Inc.</td>\n",
       "      <td>Consumer Cyclical</td>\n",
       "      <td>1.759907</td>\n",
       "      <td>High</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol                      Name             Sector  Total ESG Risk score  \\\n",
       "0   ENPH      Enphase Energy, Inc.         Technology              0.770526   \n",
       "1    EMN  Eastman Chemical Company    Basic Materials             -0.133872   \n",
       "2    DPZ       Domino's Pizza Inc.  Consumer Cyclical              1.759907   \n",
       "\n",
       "  ESG_Risk_Category Employee_Size_Category  \n",
       "0            Medium                 Medium  \n",
       "1              High                  Large  \n",
       "2              High                 Medium  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Statistical Summary of Key ESG Metrics:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Total ESG Risk score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Environment Risk Score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Governance Risk Score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Social Risk Score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Controversy Score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mv_isolation_forest_score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "403c7d04-5a2d-4899-a374-707be2103a22",
       "rows": [
        [
         "count",
         "503.0",
         "503.0",
         "503.0",
         "503.0",
         "503.0",
         "503.0"
        ],
        [
         "mean",
         "0.0",
         "-0.0",
         "0.0",
         "-0.0",
         "-0.0",
         "-0.0"
        ],
        [
         "std",
         "1.001",
         "1.001",
         "1.001",
         "1.001",
         "1.001",
         "1.001"
        ],
        [
         "min",
         "-2.588",
         "-2.289",
         "-2.103",
         "-2.389",
         "-2.414",
         "-1.987"
        ],
        [
         "25%",
         "-0.718",
         "-0.743",
         "-0.766",
         "-0.671",
         "-0.605",
         "-0.743"
        ],
        [
         "50%",
         "-0.001",
         "-0.105",
         "-0.111",
         "-0.089",
         "-0.084",
         "-0.311"
        ],
        [
         "75%",
         "0.651",
         "0.618",
         "0.575",
         "0.561",
         "0.546",
         "0.608"
        ],
        [
         "max",
         "3.534",
         "3.96",
         "3.798",
         "3.509",
         "3.867",
         "4.911"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total ESG Risk score</th>\n",
       "      <th>Environment Risk Score</th>\n",
       "      <th>Governance Risk Score</th>\n",
       "      <th>Social Risk Score</th>\n",
       "      <th>Controversy Score</th>\n",
       "      <th>mv_isolation_forest_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>503.000</td>\n",
       "      <td>503.000</td>\n",
       "      <td>503.000</td>\n",
       "      <td>503.000</td>\n",
       "      <td>503.000</td>\n",
       "      <td>503.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.001</td>\n",
       "      <td>1.001</td>\n",
       "      <td>1.001</td>\n",
       "      <td>1.001</td>\n",
       "      <td>1.001</td>\n",
       "      <td>1.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.588</td>\n",
       "      <td>-2.289</td>\n",
       "      <td>-2.103</td>\n",
       "      <td>-2.389</td>\n",
       "      <td>-2.414</td>\n",
       "      <td>-1.987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.718</td>\n",
       "      <td>-0.743</td>\n",
       "      <td>-0.766</td>\n",
       "      <td>-0.671</td>\n",
       "      <td>-0.605</td>\n",
       "      <td>-0.743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>-0.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.651</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.534</td>\n",
       "      <td>3.960</td>\n",
       "      <td>3.798</td>\n",
       "      <td>3.509</td>\n",
       "      <td>3.867</td>\n",
       "      <td>4.911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Total ESG Risk score  Environment Risk Score  Governance Risk Score  \\\n",
       "count               503.000                 503.000                503.000   \n",
       "mean                  0.000                  -0.000                  0.000   \n",
       "std                   1.001                   1.001                  1.001   \n",
       "min                  -2.588                  -2.289                 -2.103   \n",
       "25%                  -0.718                  -0.743                 -0.766   \n",
       "50%                  -0.001                  -0.105                 -0.111   \n",
       "75%                   0.651                   0.618                  0.575   \n",
       "max                   3.534                   3.960                  3.798   \n",
       "\n",
       "       Social Risk Score  Controversy Score  mv_isolation_forest_score  \n",
       "count            503.000            503.000                    503.000  \n",
       "mean              -0.000             -0.000                     -0.000  \n",
       "std                1.001              1.001                      1.001  \n",
       "min               -2.389             -2.414                     -1.987  \n",
       "25%               -0.671             -0.605                     -0.743  \n",
       "50%               -0.089             -0.084                     -0.311  \n",
       "75%                0.561              0.546                      0.608  \n",
       "max                3.509              3.867                      4.911  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Column Categories:\n",
      "   üìä Numeric: 50 columns\n",
      "   üî§ Categorical: 9 columns\n",
      "   üÜï Engineered: 10 columns\n",
      "   üé® Encoded: 26 columns\n",
      "\n",
      "‚úÖ Data preprocessing pipeline completed successfully!\n",
      "üöÄ Ready for model training and advanced analytics\n"
     ]
    }
   ],
   "source": [
    "print(\"üîç PROCESSED DATA SAMPLE PREVIEW\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"üìã Final Dataset Shape: {df_final.shape}\")\n",
    "print(f\"\\nüìä First 3 rows of key columns:\")\n",
    "key_columns = ['Symbol', 'Name', 'Sector', 'Total ESG Risk score', 'ESG_Risk_Category', 'Employee_Size_Category']\n",
    "display_cols = [col for col in key_columns if col in df_final.columns]\n",
    "if len(display_cols) > 0:\n",
    "    display(df_final[display_cols].head(3))\n",
    "print(f\"\\nüìà Statistical Summary of Key ESG Metrics:\")\n",
    "esg_metrics = [col for col in df_final.columns if any(kw in col.lower() for kw in ['esg', 'risk', 'score']) and df_final[col].dtype in [np.number]]\n",
    "if len(esg_metrics) > 0:\n",
    "    display(df_final[esg_metrics[:6]].describe().round(3))\n",
    "print(f\"\\nüéØ Column Categories:\")\n",
    "print(f\"   üìä Numeric: {len(df_final.select_dtypes(include=[np.number]).columns)} columns\")\n",
    "print(f\"   üî§ Categorical: {len(df_final.select_dtypes(include=['object']).columns)} columns\")\n",
    "print(f\"   üÜï Engineered: {len(new_features)} columns\")\n",
    "print(f\"   üé® Encoded: {len(new_encoded_cols)} columns\")\n",
    "print(f\"\\n‚úÖ Data preprocessing pipeline completed successfully!\")\n",
    "print(f\"üöÄ Ready for model training and advanced analytics\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lib-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
