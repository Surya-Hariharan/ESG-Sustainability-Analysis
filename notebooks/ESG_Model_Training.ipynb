{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1df086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('Set2')\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "plt.rcParams['axes.titlesize'] = 12print('Libraries loaded successfully')\n",
    "\n",
    "plt.rcParams['axes.labelsize'] = 10\n",
    "\n",
    "pd.set_option('display.precision', 3)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8efa03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('../data/raw/dataset.csv')\n",
    "MODEL_DIR = Path('../models')\n",
    "MODEL_PATH = MODEL_DIR / 'esg_risk_model.joblib')\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(f'Dataset Shape: {df.shape[0]:,} rows x {df.shape[1]} columns')\n",
    "print(f'Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\\n')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eb1021",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dataset Information')\n",
    "print('=' * 80)\n",
    "df.info(verbose=True, show_counts=True)\n",
    "print('\\n' + '=' * 80)\n",
    "print('Statistical Summary')\n",
    "print('=' * 80)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f57372",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "feature_cols = ['Environment Risk Score', 'Social Risk Score', 'Governance Risk Score', 'Controversy Score']\n",
    "target_col = 'ESG Risk Level'\n",
    "\n",
    "print(f'Target Variable: {target_col}')\n",
    "print(f'Feature Variables: {feature_cols}\\n')\n",
    "\n",
    "df[target_col] = df[target_col].fillna('Medium')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "df[target_col].value_counts().plot(kind='bar', ax=axes[0], color='steelblue', edgecolor='black', alpha=0.8)\n",
    "axes[0].set_title('ESG Risk Level Distribution', fontweight='bold')\n",
    "axes[0].set_xlabel('Risk Level')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "df[target_col].value_counts().plot(kind='pie', ax=axes[1], autopct='%1.1f%%', startangle=90, colors=sns.color_palette('Set2'))\n",
    "axes[1].set_title('ESG Risk Level Percentage', fontweight='bold')\n",
    "axes[1].set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(df[target_col].value_counts().to_string())\n",
    "print('\\nClass Distribution:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c68c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[feature_cols].copy()\n",
    "X.columns = ['environment_risk_score', 'social_risk_score', 'governance_risk_score', 'controversy_score']\n",
    "\n",
    "print('Missing Values Before Imputation:')\n",
    "print(X.isnull().sum())\n",
    "\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "print('\\nMissing Values After Imputation:')\n",
    "print(X.isnull().sum())\n",
    "\n",
    "label_map = {'Low': 0, 'Medium': 1, 'High': 2}\n",
    "y = df[target_col].map(label_map).fillna(1).astype(int)\n",
    "\n",
    "print(f'\\nFeature Matrix Shape: {X.shape}')\n",
    "print(f'Label Vector Shape: {y.shape}')\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "for idx, col in enumerate(X.columns):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    X[col].hist(bins=35, ax=ax, color=sns.color_palette('Set2')[idx], edgecolor='black', alpha=0.7)\n",
    "    ax.axvline(X[col].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {X[col].mean():.2f}')\n",
    "    ax.set_title(f'{col.replace(\"_\", \" \").title()} Distribution', fontweight='bold')\n",
    "    ax.set_xlabel('Score')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.show()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2a2e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "correlation = X.corr()\n",
    "\n",
    "sns.heatmap(correlation, annot=True, fmt='.3f', cmap='RdYlBu_r', square=True, \n",
    "            linewidths=1.5, cbar_kws={'shrink': 0.8}, vmin=-1, vmax=1, center=0, ax=ax)\n",
    "ax.set_title('Feature Correlation Matrix', fontweight='bold', fontsize=14, pad=20)\n",
    "\n",
    "        print(f'{col1} <-> {col2}: {corr_val:.3f}')\n",
    "\n",
    "plt.tight_layout()        corr_val = correlation.loc[col1, col2]\n",
    "\n",
    "plt.show()    for col2 in X.columns[i+1:]:\n",
    "\n",
    "for i, col1 in enumerate(X.columns):\n",
    "print('\\nCorrelation Analysis:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27b8e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE)\n",
    "\n",
    "print('Train/Test Split (80/20):')\n",
    "print('=' * 80)\n",
    "print(f'Training Samples: {X_train.shape[0]:,} ({X_train.shape[0]/len(X)*100:.1f}%)')\n",
    "print(f'Testing Samples:  {X_test.shape[0]:,} ({X_test.shape[0]/len(X)*100:.1f}%)')\n",
    "\n",
    "print('\\nTraining Set - Class Distribution:')\n",
    "print(y_train.value_counts().sort_index().to_string())\n",
    "\n",
    "print('\\nTesting Set - Class Distribution:')\n",
    "print(y_test.value_counts().sort_index().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e971bb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=20,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        random_state=RANDOM_STATE,\n",
    "        class_weight='balanced',\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    ))\n",
    "])\n",
    "\n",
    "print('ML Pipeline Architecture:')\n",
    "print('=' * 80)\n",
    "for step_name, step_obj in pipeline.steps:\n",
    "    print(f'{step_name}: {step_obj.__class__.__name__}')\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecab6df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training model...')\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "train_score = pipeline.score(X_train, y_train)\n",
    "test_score = pipeline.score(X_test, y_test)\n",
    "\n",
    "print('\\nTraining Complete')\n",
    "print('=' * 80)\n",
    "print(f'Training Accuracy:   {train_score:.4f} ({train_score*100:.2f}%)')\n",
    "print(f'Testing Accuracy:    {test_score:.4f} ({test_score*100:.2f}%)')\n",
    "\n",
    "print(f'Generalization Gap:  {abs(train_score - test_score):.4f} ({abs(train_score - test_score)*100:.2f}%)')print('=' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e669d4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Performing 5-Fold Cross-Validation...')\n",
    "cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print('=' * 80)\n",
    "print(f'Fold Scores: {[\"{:.4f}\".format(score) for score in cv_scores]}')\n",
    "print(f'Mean CV Accuracy: {cv_scores.mean():.4f} +/- {cv_scores.std():.4f}')\n",
    "print(f'Min CV Accuracy:  {cv_scores.min():.4f}')\n",
    "\n",
    "print(f'Max CV Accuracy:  {cv_scores.max():.4f}')print('=' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddb9453",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "y_pred_proba = pipeline.predict_proba(X_test)\n",
    "\n",
    "print('Classification Report:')\n",
    "print('=' * 80)\n",
    "print(classification_report(y_test, y_pred, target_names=['Low Risk (0)', 'Medium Risk (1)', 'High Risk (2)'], digits=4))\n",
    "\n",
    "macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "weighted_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print('Overall Performance Metrics:')\n",
    "print('=' * 80)\n",
    "print(f'Accuracy:          {accuracy:.4f}')\n",
    "print(f'Macro F1 Score:    {macro_f1:.4f}')\n",
    "\n",
    "print(f'Weighted F1 Score: {weighted_f1:.4f}')print('=' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdd5932",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', square=True, linewidths=2,\n",
    "            xticklabels=['Low', 'Medium', 'High'],\n",
    "            yticklabels=['Low', 'Medium', 'High'],\n",
    "            cbar_kws={'shrink': 0.8}, ax=ax)\n",
    "ax.set_title('Confusion Matrix - ESG Risk Prediction', fontweight='bold', fontsize=14, pad=20)\n",
    "ax.set_xlabel('Predicted Risk Level', fontweight='bold')\n",
    "ax.set_ylabel('Actual Risk Level', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nConfusion Matrix (Raw Counts):')\n",
    "\n",
    "print('=' * 80)                   columns=['Pred Low', 'Pred Medium', 'Pred High']).round(2))\n",
    "\n",
    "print(cm)                   index=['Actual Low', 'Actual Medium', 'Actual High'],\n",
    "\n",
    "print('\\nNormalized Confusion Matrix (Percentages):')print(pd.DataFrame(cm_normalized, \n",
    "\n",
    "print('=' * 80)cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490570fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pipeline.named_steps['classifier'].feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importance\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "colors = sns.color_palette('viridis', len(importance_df))\n",
    "ax.barh(importance_df['Feature'], importance_df['Importance'], color=colors, edgecolor='black')\n",
    "ax.set_xlabel('Importance Score', fontweight='bold')\n",
    "ax.set_ylabel('Features', fontweight='bold')\n",
    "ax.set_title('Feature Importance - Random Forest Classifier', fontweight='bold', fontsize=14)\n",
    "ax.invert_yaxis()\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "for i, (idx, row) in enumerate(importance_df.iterrows()):\n",
    "    ax.text(row['Importance'] + 0.01, i, f\"{row['Importance']:.4f}\", va='center')\n",
    "\n",
    "\n",
    "plt.tight_layout()print('=' * 80)\n",
    "\n",
    "plt.show()    print(f\"{row['Feature']:30s}: {row['Importance']:.4f} ({row['Importance']*100:.2f}%)\")\n",
    "\n",
    "for i, row in importance_df.iterrows():\n",
    "\n",
    "print('\\nFeature Importance Ranking:')print('=' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13347728",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "joblib.dump(pipeline, MODEL_PATH)\n",
    "\n",
    "file_size = MODEL_PATH.stat().st_size\n",
    "print('Model Saved Successfully')\n",
    "print('=' * 80)\n",
    "print(f'Location: {MODEL_PATH}')\n",
    "print(f'Size: {file_size / 1024:.2f} KB ({file_size / (1024*1024):.2f} MB)')\n",
    "print(f'Components: {len(pipeline.steps)} pipeline steps')\n",
    "\n",
    "print(f'Estimators: {pipeline.named_steps[\"classifier\"].n_estimators}')print('=' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d21ccbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = joblib.load(MODEL_PATH)\n",
    "verification_predictions = loaded_model.predict(X_test[:10])\n",
    "verification_probas = loaded_model.predict_proba(X_test[:10])\n",
    "\n",
    "print('Model Verification:')\n",
    "print('=' * 80)\n",
    "print(f'Loaded Model Type: {type(loaded_model).__name__}')\n",
    "print(f'Pipeline Steps: {list(loaded_model.named_steps.keys())}')\n",
    "print(f'Number of Classes: {len(loaded_model.classes_)}')\n",
    "print(f'Classes: {loaded_model.classes_}')\n",
    "\n",
    "\n",
    "print('\\nFirst 10 Test Samples - Predictions:')print('Model verified and ready for production deployment')\n",
    "\n",
    "print('=' * 80)print(f'Accuracy on sample: {comparison_df[\"Match\"].sum()}/10 ({comparison_df[\"Match\"].mean()*100:.1f}%)')\n",
    "\n",
    "comparison_df = pd.DataFrame({print('=' * 80)\n",
    "\n",
    "    'Actual': y_test[:10].values,print(comparison_df.to_string())\n",
    "\n",
    "    'Predicted': verification_predictions,})\n",
    "    'Match': y_test[:10].values == verification_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939f5b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = pd.DataFrame({\n",
    "    'environment_risk_score': [15.5, 35.2, 8.1],\n",
    "    'social_risk_score': [12.3, 28.7, 5.6],\n",
    "    'governance_risk_score': [10.1, 25.4, 4.2],\n",
    "    'controversy_score': [5.0, 45.0, 2.0]\n",
    "})\n",
    "\n",
    "predictions = loaded_model.predict(sample_data)\n",
    "probabilities = loaded_model.predict_proba(sample_data)\n",
    "\n",
    "risk_labels = {0: 'Low Risk', 1: 'Medium Risk', 2: 'High Risk'}\n",
    "\n",
    "print('Sample Predictions - Demonstration:')\n",
    "print('=' * 80)\n",
    "for i in range(len(sample_data)):\n",
    "    print(f\"\\nSample {i+1}:\")\n",
    "    print(f\"  Environment Risk Score: {sample_data.iloc[i]['environment_risk_score']:.1f}\")\n",
    "    print(f\"  Social Risk Score:      {sample_data.iloc[i]['social_risk_score']:.1f}\")\n",
    "    print(f\"  Governance Risk Score:  {sample_data.iloc[i]['governance_risk_score']:.1f}\")\n",
    "    print(f\"  Controversy Score:      {sample_data.iloc[i]['controversy_score']:.1f}\")\n",
    "    print(f\"  Predicted Risk Level: {risk_labels[predictions[i]]}\")\n",
    "    print(f\"  Confidence Distribution:\")\n",
    "    print(f\"    Low Risk:    {probabilities[i][0]:.4f} ({probabilities[i][0]*100:.2f}%)\")\n",
    "\n",
    "    print(f\"    Medium Risk: {probabilities[i][1]:.4f} ({probabilities[i][1]*100:.2f}%)\")print('=' * 80)\n",
    "    print(f\"    High Risk:   {probabilities[i][2]:.4f} ({probabilities[i][2]*100:.2f}%)\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
